{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdb9781",
   "metadata": {},
   "source": [
    "# Feature Engineering — TMDB Movie Revenue & Popularity Prediction\n",
    "\n",
    "**Purpose:** Transform raw TMDB movie data into a clean, target-agnostic master feature dataset that supports both supervised and semi-supervised modeling for revenue and popularity prediction.\n",
    "\n",
    "**Key Principles:**\n",
    "- **Target-agnostic master dataset:** We create `data_features_master` containing ALL pre-release features plus raw revenue, popularity, and budget — without filtering for any specific target.\n",
    "- **Zero correction:** Budget and revenue values of 0 are treated as missing (replaced with NaN) and tracked with binary flags.\n",
    "- **No data leakage:** Post-release metrics (vote_average, vote_count) are excluded from feature matrices at modeling time, not deleted from the master.\n",
    "- **Semi-supervised ready:** Rows with missing revenue remain in the dataset as unlabeled observations (y = -1) for SSL classifiers.\n",
    "- **Revenue tiers:** Computed only from labeled (non-NaN revenue) observations using quantile-based binning.\n",
    "\n",
    "**Feature Categories:**\n",
    "1. Talent Features (cast & director signals)\n",
    "2. Content Features (genres, keywords, language)\n",
    "3. Temporal Features (release timing & seasonality)\n",
    "4. Production Features (budget, runtime)\n",
    "\n",
    "**Output Datasets:**\n",
    "- `data_features_master.csv` — neutral master (all rows, all features, raw targets)\n",
    "- `data_supervised_revenue.csv` — labeled rows only, no post-release features\n",
    "- `data_supervised_popularity.csv` — labeled rows only, no revenue features\n",
    "- `data_ssl_revenue.csv` — all rows with y_ssl column for semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c2faea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd09b5",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load the raw TMDB dataset and drop the unnamed index column carried over from the CSV export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec0c2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9290, 51)\n",
      "Columns: ['movie_id', 'title', 'release_date', 'runtime', 'original_language', 'popularity', 'vote_average', 'vote_count', 'budget', 'revenue', 'status', 'overview', 'genres', 'keywords', 'director_id', 'director_name', 'director_gender', 'director_popularity', 'director_department', 'actor1_id', 'actor1_name', 'actor1_character', 'actor1_gender', 'actor1_popularity', 'actor1_department', 'actor2_id', 'actor2_name', 'actor2_character', 'actor2_gender', 'actor2_popularity', 'actor2_department', 'actor3_id', 'actor3_name', 'actor3_character', 'actor3_gender', 'actor3_popularity', 'actor3_department', 'actor4_id', 'actor4_name', 'actor4_character', 'actor4_gender', 'actor4_popularity', 'actor4_department', 'actor5_id', 'actor5_name', 'actor5_character', 'actor5_gender', 'actor5_popularity', 'actor5_department', 'cast_pop_mean', 'cast_pop_max']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load raw data\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"../data/movies_2010_2025.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2d57e",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Reusable parsing utilities inherited from the EDA phase. The `safe_parse_list` function handles the genres and keywords columns, which are stored as string representations of Python lists in the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54e314a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Helper: safely parse stringified lists from CSV\n",
    "# ============================================================\n",
    "def safe_parse_list(x):\n",
    "    \"\"\"\n",
    "    Convert stringified lists (e.g., \"['Action', 'Drama']\") back into\n",
    "    actual Python lists. Handles NaN, empty strings, and edge cases.\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, float) and pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        if x == \"\" or x == \"[]\":\n",
    "            return []\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c35d6c",
   "metadata": {},
   "source": [
    "## 3. Column Classification — Pre-Release vs Post-Release\n",
    "\n",
    "We classify every column as pre-release (available before the movie opens) or post-release (only known after release). This classification drives all downstream dataset construction.\n",
    "\n",
    "**Pre-release features (valid for modeling):**\n",
    "- Temporal: release_year, release_month, release_quarter, is_summer_release, is_holiday_release\n",
    "- Cast: actor1-5 popularity, cast_pop_mean, cast_pop_max, star_count, cast_popularity_std, cast_gender_ratio\n",
    "- Director: director_popularity, director_is_female\n",
    "- Content: genre_* (one-hot), num_genres, keyword_count, lang_* encodings, is_english\n",
    "- Production: runtime, has_budget, log_budget\n",
    "- Text signal: has_overview, overview_length\n",
    "\n",
    "**Post-release variables (kept in master, excluded from feature matrices):**\n",
    "- popularity, vote_average, vote_count\n",
    "\n",
    "**Raw target variables (kept in master for target construction):**\n",
    "- revenue, budget (raw values preserved alongside engineered versions)\n",
    "\n",
    "**Identifier / non-predictive columns (dropped from master):**\n",
    "- movie_id, title, status, overview, all name/character/department/ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99226812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-release columns (kept in master, excluded from features): ['popularity', 'vote_average', 'vote_count']\n",
      "Raw target columns (kept in master for target construction): ['revenue', 'budget']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Classify columns: post-release metrics to keep in master\n",
    "# but exclude from feature matrices during modeling\n",
    "# ============================================================\n",
    "post_release_cols = [\"popularity\", \"vote_average\", \"vote_count\"]\n",
    "raw_target_cols = [\"revenue\", \"budget\"]\n",
    "\n",
    "print(\"Post-release columns (kept in master, excluded from features):\", post_release_cols)\n",
    "print(\"Raw target columns (kept in master for target construction):\", raw_target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dddc7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns excluded from master: 27\n",
      "Excluded: ['movie_id', 'title', 'status', 'overview', 'director_id', 'director_name', 'director_department', 'actor1_id', 'actor1_name', 'actor1_character', 'actor1_department', 'actor2_id', 'actor2_name', 'actor2_character', 'actor2_department', 'actor3_id', 'actor3_name', 'actor3_character', 'actor3_department', 'actor4_id', 'actor4_name', 'actor4_character', 'actor4_department', 'actor5_id', 'actor5_name', 'actor5_character', 'actor5_department']\n",
      "\n",
      "NOTE: revenue, budget, popularity, vote_average, vote_count are KEPT in the master.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Define columns to exclude from the MASTER dataset entirely\n",
    "# (identifiers, free text, high-cardinality names, near-zero variance departments)\n",
    "# ============================================================\n",
    "id_cols = [\"movie_id\", \"title\"]\n",
    "\n",
    "non_predictive_cols = [\n",
    "    \"status\", \"overview\",\n",
    "    \"director_id\", \"director_name\", \"director_department\",\n",
    "    \"actor1_id\", \"actor1_name\", \"actor1_character\", \"actor1_department\",\n",
    "    \"actor2_id\", \"actor2_name\", \"actor2_character\", \"actor2_department\",\n",
    "    \"actor3_id\", \"actor3_name\", \"actor3_character\", \"actor3_department\",\n",
    "    \"actor4_id\", \"actor4_name\", \"actor4_character\", \"actor4_department\",\n",
    "    \"actor5_id\", \"actor5_name\", \"actor5_character\", \"actor5_department\",\n",
    "]\n",
    "\n",
    "# These are dropped from the master dataset entirely\n",
    "all_excluded_from_master = id_cols + non_predictive_cols\n",
    "\n",
    "print(f\"Total columns excluded from master: {len(all_excluded_from_master)}\")\n",
    "print(f\"Excluded: {all_excluded_from_master}\")\n",
    "print(f\"\\nNOTE: revenue, budget, popularity, vote_average, vote_count are KEPT in the master.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba9375",
   "metadata": {},
   "source": [
    "## 4. Parse List Columns\n",
    "\n",
    "The `genres` and `keywords` columns are stored as stringified Python lists in the CSV. We parse them into actual lists before engineering features from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f1c7667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample genres: ['Action', 'Science Fiction', 'Adventure']\n",
      "Sample keywords: ['rescue', 'mission', 'dreams', 'airplane', 'paris, france', 'virtual reality', 'kidnapping', 'philosophy', 'spy', 'allegory', 'manipulation', 'car crash', 'heist', 'memory', 'architecture', 'los angeles, california', 'death', 'dream world', 'subconscious', 'dream']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Parse genres and keywords from strings to lists\n",
    "# ============================================================\n",
    "df[\"genres\"] = df[\"genres\"].apply(safe_parse_list)\n",
    "df[\"keywords\"] = df[\"keywords\"].apply(safe_parse_list)\n",
    "\n",
    "# Quick verification\n",
    "print(\"Sample genres:\", df[\"genres\"].iloc[0])\n",
    "print(\"Sample keywords:\", df[\"keywords\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a53c4",
   "metadata": {},
   "source": [
    "## 5. Temporal Features — Release Timing & Seasonality\n",
    "\n",
    "Movie success is heavily influenced by **when** it is released. Summer blockbuster season, holiday releases, and award-season timing are well-known industry patterns.\n",
    "\n",
    "**Features engineered:**\n",
    "- `release_month` — captures monthly seasonality (e.g., June/July for summer blockbusters, Nov/Dec for awards and holidays)\n",
    "- `release_year` — captures long-term industry trends (e.g., streaming era shifts)\n",
    "- `release_quarter` — a coarser seasonal signal (Q1-Q4)\n",
    "- `is_summer_release` — binary flag for the peak blockbuster window (May-July)\n",
    "- `is_holiday_release` — binary flag for the holiday corridor (November-December)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad4ccc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal features created:\n",
      "       release_month  release_year  release_quarter  is_summer_release  \\\n",
      "count    9290.000000   9290.000000      9290.000000        9290.000000   \n",
      "mean        6.752530   2017.456512         2.587406           0.218837   \n",
      "std         3.463668      4.623364         1.136100           0.413480   \n",
      "min         1.000000   2010.000000         1.000000           0.000000   \n",
      "25%         4.000000   2013.000000         2.000000           0.000000   \n",
      "50%         7.000000   2017.000000         3.000000           0.000000   \n",
      "75%        10.000000   2021.000000         4.000000           0.000000   \n",
      "max        12.000000   2025.000000         4.000000           1.000000   \n",
      "\n",
      "       is_holiday_release  \n",
      "count         9290.000000  \n",
      "mean             0.164155  \n",
      "std              0.370436  \n",
      "min              0.000000  \n",
      "25%              0.000000  \n",
      "50%              0.000000  \n",
      "75%              0.000000  \n",
      "max              1.000000  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Temporal features from release_date\n",
    "# ============================================================\n",
    "df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "\n",
    "# Month and year\n",
    "df[\"release_month\"] = df[\"release_date\"].dt.month\n",
    "df[\"release_year\"] = df[\"release_date\"].dt.year\n",
    "\n",
    "# Quarter (1-4)\n",
    "df[\"release_quarter\"] = df[\"release_date\"].dt.quarter\n",
    "\n",
    "# Summer release: May (5), June (6), July (7)\n",
    "df[\"is_summer_release\"] = df[\"release_month\"].isin([5, 6, 7]).astype(int)\n",
    "\n",
    "# Holiday release: November (11), December (12)\n",
    "df[\"is_holiday_release\"] = df[\"release_month\"].isin([11, 12]).astype(int)\n",
    "\n",
    "# Handle the 1 missing release_date - fill temporal features with median\n",
    "for col in [\"release_month\", \"release_year\", \"release_quarter\"]:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "print(\"Temporal features created:\")\n",
    "print(df[[\"release_month\", \"release_year\", \"release_quarter\",\n",
    "          \"is_summer_release\", \"is_holiday_release\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b9061",
   "metadata": {},
   "source": [
    "## 6. Talent Features — Cast & Director Signals\n",
    "\n",
    "The star power of a film's cast and director is one of the strongest pre-release indicators of audience interest. The dataset already provides individual actor popularities (actor1-5) and aggregated stats (`cast_pop_mean`, `cast_pop_max`). We engineer additional features to capture richer talent signals.\n",
    "\n",
    "**Features engineered:**\n",
    "- `director_popularity` — already exists in the data, retained as-is\n",
    "- `director_is_female` — binary flag (TMDB gender encoding: 1 = Female, 2 = Male)\n",
    "- `star_count` — number of actors (out of top 5 billed) whose popularity exceeds the 75th percentile across all actors; captures how many recognizable names are attached\n",
    "- `cast_popularity_std` — standard deviation of top 5 actors' popularities; high std = one big name + unknowns, low std = balanced ensemble\n",
    "- `cast_gender_ratio` — proportion of female actors in the top 5 billed cast\n",
    "- `cast_pop_mean`, `cast_pop_max` — already exist, retained as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5981b1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star threshold (75th percentile of non-zero actor popularity): 2.9868\n",
      "\n",
      "Talent features summary:\n",
      "        star_count  cast_popularity_std  cast_gender_ratio  \\\n",
      "count  9290.000000          9290.000000        9290.000000   \n",
      "mean      1.147578             1.260020           0.412983   \n",
      "std       1.364494             1.767775           0.259384   \n",
      "min       0.000000             0.000000           0.000000   \n",
      "25%       0.000000             0.576811           0.200000   \n",
      "50%       1.000000             1.017833           0.400000   \n",
      "75%       2.000000             1.516547           0.600000   \n",
      "max       5.000000            84.167164           1.000000   \n",
      "\n",
      "       director_is_female  director_popularity  cast_pop_mean  cast_pop_max  \n",
      "count         9290.000000          9290.000000    9290.000000   9290.000000  \n",
      "mean             0.116685             1.209358       2.023336      4.085244  \n",
      "std              0.321061             1.361564       1.876921      4.903623  \n",
      "min              0.000000             0.000000       0.000000      0.000000  \n",
      "25%              0.000000             0.248600       0.836880      1.985875  \n",
      "50%              0.000000             0.656450       1.553430      3.254900  \n",
      "75%              0.000000             1.745450       2.775495      4.993100  \n",
      "max              1.000000            20.877800      56.784000    224.150000  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Talent features\n",
    "# ============================================================\n",
    "\n",
    "# --- Actor popularity columns ---\n",
    "actor_pop_cols = [f\"actor{i}_popularity\" for i in range(1, 6)]\n",
    "actor_gender_cols = [f\"actor{i}_gender\" for i in range(1, 6)]\n",
    "\n",
    "# --- Star count ---\n",
    "# Define \"star\" threshold as 75th percentile of all non-zero actor popularities\n",
    "all_actor_pops = df[actor_pop_cols].values.flatten()\n",
    "all_actor_pops_nonzero = all_actor_pops[all_actor_pops > 0]\n",
    "star_threshold = np.percentile(all_actor_pops_nonzero, 75)\n",
    "print(f\"Star threshold (75th percentile of non-zero actor popularity): {star_threshold:.4f}\")\n",
    "\n",
    "# Count how many of the 5 actors exceed the star threshold per movie\n",
    "df[\"star_count\"] = (df[actor_pop_cols] > star_threshold).sum(axis=1)\n",
    "\n",
    "# --- Cast popularity standard deviation ---\n",
    "# Measures whether the cast is balanced or relies on a single star\n",
    "df[\"cast_popularity_std\"] = df[actor_pop_cols].apply(\n",
    "    lambda row: np.std([x for x in row if x > 0]) if any(x > 0 for x in row) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- Cast gender ratio (proportion female) ---\n",
    "# TMDB gender encoding: 1 = Female, 2 = Male, 0 = Unknown/Not set\n",
    "def calc_female_ratio(row):\n",
    "    known = [g for g in row if g in (1.0, 2.0)]\n",
    "    if len(known) == 0:\n",
    "        return 0.5  # default to balanced when unknown\n",
    "    return sum(1 for g in known if g == 1.0) / len(known)\n",
    "\n",
    "df[\"cast_gender_ratio\"] = df[actor_gender_cols].apply(calc_female_ratio, axis=1)\n",
    "\n",
    "# --- Director is female ---\n",
    "df[\"director_is_female\"] = (df[\"director_gender\"] == 1.0).astype(int)\n",
    "\n",
    "print(\"\\nTalent features summary:\")\n",
    "print(df[[\"star_count\", \"cast_popularity_std\", \"cast_gender_ratio\",\n",
    "          \"director_is_female\", \"director_popularity\",\n",
    "          \"cast_pop_mean\", \"cast_pop_max\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf239bf",
   "metadata": {},
   "source": [
    "## 7. Content Features — Genre Encoding\n",
    "\n",
    "Genres are a core signal for audience interest. Since a movie can belong to multiple genres, we use **multi-hot encoding** — each genre becomes a binary column (1 if the movie belongs to that genre, 0 otherwise).\n",
    "\n",
    "We also create `num_genres` to capture the breadth of a movie's genre classification. Movies spanning many genres may have broader audience appeal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc1eeb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique genres found: 19\n",
      "Genres: ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western']\n",
      "\n",
      "Genre feature columns created: 19 binary + 1 count\n",
      "num_genres distribution:\n",
      "count    9290.000000\n",
      "mean        1.988482\n",
      "std         1.108486\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         3.000000\n",
      "max         8.000000\n",
      "Name: num_genres, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Multi-hot encode genres\n",
    "# ============================================================\n",
    "\n",
    "# Get all unique genres across the dataset\n",
    "all_genres = sorted(set(g for genres_list in df[\"genres\"] for g in genres_list))\n",
    "print(f\"Total unique genres found: {len(all_genres)}\")\n",
    "print(f\"Genres: {all_genres}\")\n",
    "\n",
    "# Create binary columns for each genre\n",
    "for genre in all_genres:\n",
    "    df[f\"genre_{genre}\"] = df[\"genres\"].apply(lambda x, g=genre: 1 if g in x else 0)\n",
    "\n",
    "# Number of genres per movie\n",
    "df[\"num_genres\"] = df[\"genres\"].apply(len)\n",
    "\n",
    "print(f\"\\nGenre feature columns created: {len(all_genres)} binary + 1 count\")\n",
    "print(f\"num_genres distribution:\\n{df['num_genres'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34114962",
   "metadata": {},
   "source": [
    "## 8. Content Features — Keyword Count\n",
    "\n",
    "Rather than encoding individual keywords (which would create thousands of extremely sparse columns), we use the **keyword count** as a proxy for how richly tagged a movie is. Movies with more keywords tend to have more developed marketing and metadata, which itself correlates with production scale and audience reach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "324684e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword_count distribution:\n",
      "count    9290.000000\n",
      "mean        5.189020\n",
      "std         7.172168\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         2.000000\n",
      "75%         8.000000\n",
      "max       101.000000\n",
      "Name: keyword_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Keyword count\n",
    "# ============================================================\n",
    "df[\"keyword_count\"] = df[\"keywords\"].apply(len)\n",
    "\n",
    "print(\"keyword_count distribution:\")\n",
    "print(df[\"keyword_count\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c3f1f",
   "metadata": {},
   "source": [
    "## 9. Content Features — Original Language Encoding\n",
    "\n",
    "The EDA showed that English (`en`) dominates the dataset, with a long tail of other languages. We use a **top-K encoding** strategy:\n",
    "\n",
    "- The top 5 most frequent languages each get their own binary column.\n",
    "- All remaining languages are grouped into `lang_other`.\n",
    "- A simple `is_english` flag captures the most important language split for global popularity prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd14201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 languages: ['en', 'fr', 'es', 'ja', 'de']\n",
      "\n",
      "is_english distribution:\n",
      "is_english\n",
      "1    5748\n",
      "0    3542\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Language encoding (top-K + is_english flag)\n",
    "# ============================================================\n",
    "\n",
    "# Identify top 5 languages by frequency\n",
    "top_languages = df[\"original_language\"].value_counts().head(5).index.tolist()\n",
    "print(f\"Top 5 languages: {top_languages}\")\n",
    "\n",
    "# Create binary column for each top language\n",
    "for lang in top_languages:\n",
    "    df[f\"lang_{lang}\"] = (df[\"original_language\"] == lang).astype(int)\n",
    "\n",
    "# Catch-all for less common languages\n",
    "df[\"lang_other\"] = (~df[\"original_language\"].isin(top_languages)).astype(int)\n",
    "\n",
    "# Simple is_english flag\n",
    "df[\"is_english\"] = (df[\"original_language\"] == \"en\").astype(int)\n",
    "\n",
    "print(f\"\\nis_english distribution:\\n{df['is_english'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a86d94",
   "metadata": {},
   "source": [
    "## 10. Production Features — Budget, Revenue Zero Correction & Runtime\n",
    "\n",
    "**Zero Correction:** In TMDB, `budget = 0` and `revenue = 0` mean \"not reported\", not truly $0. We:\n",
    "1. Replace `budget == 0` → `NaN` and `revenue == 0` → `NaN`\n",
    "2. Create `budget_missing_flag` and `revenue_missing_flag` (1 = missing, 0 = present)\n",
    "3. **Do NOT drop rows** with missing revenue — these define unlabeled observations for semi-supervised learning\n",
    "\n",
    "**Budget features:**\n",
    "- `has_budget` — binary flag (1 if budget is known)\n",
    "- `log_budget` — log1p transform (0 for missing budgets)\n",
    "- `budget_missing_flag` — 1 if budget was 0/NaN\n",
    "\n",
    "**Revenue handling:**\n",
    "- `revenue_missing_flag` — 1 if revenue was 0/NaN\n",
    "- Raw `revenue` is preserved in the master for target construction\n",
    "\n",
    "**Runtime:** Retained as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e2a7c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue: 6686 zeros replaced with NaN\n",
      "revenue_missing_flag distribution:\n",
      "{1: 6686, 0: 2604}\n",
      "\n",
      "Budget: 6527 zeros replaced with NaN\n",
      "budget_missing_flag distribution:\n",
      "{1: 6527, 0: 2763}\n",
      "\n",
      "has_budget distribution: {0: 6527, 1: 2763}\n",
      "log_budget stats (where budget known):\n",
      "count    2763.000000\n",
      "mean       15.833550\n",
      "std         3.021456\n",
      "min         0.693147\n",
      "25%        14.978662\n",
      "50%        16.705882\n",
      "75%        17.727534\n",
      "max        20.009712\n",
      "Name: log_budget, dtype: float64\n",
      "\n",
      "Runtime stats:\n",
      "count    9290.000000\n",
      "mean       81.390635\n",
      "std        44.067500\n",
      "min         0.000000\n",
      "25%        67.000000\n",
      "50%        92.000000\n",
      "75%       107.000000\n",
      "max       950.000000\n",
      "Name: runtime, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Production features: Budget & Revenue zero correction, Runtime\n",
    "# ============================================================\n",
    "\n",
    "# --- Revenue: replace 0 with NaN ---\n",
    "revenue_zero_count = (df[\"revenue\"] == 0).sum()\n",
    "df[\"revenue\"] = df[\"revenue\"].replace(0, np.nan)\n",
    "df[\"revenue_missing_flag\"] = df[\"revenue\"].isna().astype(int)\n",
    "print(f\"Revenue: {revenue_zero_count} zeros replaced with NaN\")\n",
    "print(f\"revenue_missing_flag distribution:\\n{df['revenue_missing_flag'].value_counts().to_dict()}\")\n",
    "\n",
    "# --- Budget: replace 0 with NaN ---\n",
    "budget_zero_count = (df[\"budget\"] == 0).sum()\n",
    "df[\"budget\"] = df[\"budget\"].replace(0, np.nan)\n",
    "df[\"budget_missing_flag\"] = df[\"budget\"].isna().astype(int)\n",
    "print(f\"\\nBudget: {budget_zero_count} zeros replaced with NaN\")\n",
    "print(f\"budget_missing_flag distribution:\\n{df['budget_missing_flag'].value_counts().to_dict()}\")\n",
    "\n",
    "# --- Budget engineered features ---\n",
    "df[\"has_budget\"] = (df[\"budget\"].notna()).astype(int)\n",
    "df[\"log_budget\"] = np.log1p(df[\"budget\"].fillna(0))\n",
    "\n",
    "print(f\"\\nhas_budget distribution: {df['has_budget'].value_counts().to_dict()}\")\n",
    "print(f\"log_budget stats (where budget known):\")\n",
    "print(df.loc[df[\"budget\"].notna(), \"log_budget\"].describe())\n",
    "\n",
    "# --- Runtime ---\n",
    "print(f\"\\nRuntime stats:\\n{df['runtime'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e1cec",
   "metadata": {},
   "source": [
    "## 11. Text Signal — Overview Availability\n",
    "\n",
    "The movie overview (synopsis) is free text that would require NLP to fully exploit. For this pipeline, we extract a simple but meaningful signal: **whether an overview exists and how long it is**. Movies with longer, more detailed overviews tend to have more developed marketing and distribution — a lightweight proxy for production effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6f93234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview features:\n",
      "  has_overview: {1: 9089, 0: 201}\n",
      "  overview_length stats:\n",
      "count    9290.000000\n",
      "mean      259.595048\n",
      "std       164.951892\n",
      "min         0.000000\n",
      "25%       146.000000\n",
      "50%       220.000000\n",
      "75%       339.000000\n",
      "max       999.000000\n",
      "Name: overview_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Overview-based features\n",
    "# ============================================================\n",
    "\n",
    "# Whether the movie has an overview at all\n",
    "df[\"has_overview\"] = df[\"overview\"].notna().astype(int)\n",
    "\n",
    "# Length of overview (character count)\n",
    "df[\"overview_length\"] = df[\"overview\"].fillna(\"\").apply(len)\n",
    "\n",
    "print(\"Overview features:\")\n",
    "print(f\"  has_overview: {df['has_overview'].value_counts().to_dict()}\")\n",
    "print(f\"  overview_length stats:\\n{df['overview_length'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed95812",
   "metadata": {},
   "source": [
    "## 12. Assemble Neutral Master Feature Dataset\n",
    "\n",
    "Create `data_features_master` — a target-agnostic dataset containing:\n",
    "- All pre-release engineered features\n",
    "- Raw revenue and raw popularity (for target construction)\n",
    "- Raw budget (preserved alongside log_budget and has_budget)\n",
    "- Missing flags (revenue_missing_flag, budget_missing_flag)\n",
    "- Post-release metrics (vote_average, vote_count) — kept in master, excluded at modeling time\n",
    "\n",
    "**No rows are dropped. No target-specific filtering.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e23b999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataset shape: (9290, 57)\n",
      "\n",
      "All columns (57):\n",
      "['runtime', 'popularity', 'vote_average', 'vote_count', 'budget', 'revenue', 'director_popularity', 'actor1_popularity', 'actor2_popularity', 'actor3_popularity', 'actor4_popularity', 'actor5_popularity', 'cast_pop_mean', 'cast_pop_max', 'release_month', 'release_year', 'release_quarter', 'is_summer_release', 'is_holiday_release', 'star_count', 'cast_popularity_std', 'cast_gender_ratio', 'director_is_female', 'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', 'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western', 'num_genres', 'keyword_count', 'lang_en', 'lang_fr', 'lang_es', 'lang_ja', 'lang_de', 'lang_other', 'is_english', 'revenue_missing_flag', 'budget_missing_flag', 'has_budget', 'log_budget', 'has_overview', 'overview_length']\n",
      "\n",
      "--- Confirming key columns are present ---\n",
      "  revenue: YES\n",
      "  popularity: YES\n",
      "  budget: YES\n",
      "  vote_average: YES\n",
      "  vote_count: YES\n",
      "  revenue_missing_flag: YES\n",
      "  budget_missing_flag: YES\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Assemble the neutral master feature dataset\n",
    "# ============================================================\n",
    "\n",
    "# Drop only non-predictive/identifier columns and intermediate raw columns\n",
    "cols_to_drop_from_master = (\n",
    "    all_excluded_from_master\n",
    "    + [\"release_date\", \"original_language\", \"genres\", \"keywords\",\n",
    "       \"director_gender\",                             # replaced by director_is_female\n",
    "       \"actor1_gender\", \"actor2_gender\", \"actor3_gender\",\n",
    "       \"actor4_gender\", \"actor5_gender\",              # replaced by cast_gender_ratio\n",
    "       ]\n",
    ")\n",
    "\n",
    "# Only drop columns that actually exist\n",
    "cols_to_drop_existing = [c for c in cols_to_drop_from_master if c in df.columns]\n",
    "\n",
    "data_features_master = df.drop(columns=cols_to_drop_existing)\n",
    "\n",
    "print(f\"Master dataset shape: {data_features_master.shape}\")\n",
    "print(f\"\\nAll columns ({len(data_features_master.columns)}):\")\n",
    "print(list(data_features_master.columns))\n",
    "print(f\"\\n--- Confirming key columns are present ---\")\n",
    "for col in [\"revenue\", \"popularity\", \"budget\", \"vote_average\", \"vote_count\",\n",
    "            \"revenue_missing_flag\", \"budget_missing_flag\"]:\n",
    "    present = col in data_features_master.columns\n",
    "    print(f\"  {col}: {'YES' if present else 'MISSING!'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a80eb5b",
   "metadata": {},
   "source": [
    "## 13. Create Revenue Tier\n",
    "\n",
    "Revenue tiers are computed **only from rows where revenue is not NaN** (labeled observations). Quantile thresholds are calculated exclusively from labeled data.\n",
    "\n",
    "**Tiers:** Low, Medium, High, Blockbuster (based on quartiles)\n",
    "**Unlabeled rows:** revenue_tier = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c34c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled rows (revenue not NaN): 2604\n",
      "Unlabeled rows (revenue is NaN): 6686\n",
      "\n",
      "Revenue quantile thresholds (from labeled data only):\n",
      "  Q25 (Low/Medium boundary):       $3,553,760\n",
      "  Q50 (Medium/High boundary):       $33,749,242\n",
      "  Q75 (High/Blockbuster boundary):  $140,441,440\n",
      "\n",
      "Revenue tier distribution (labeled rows only):\n",
      "revenue_tier\n",
      "Low            651\n",
      "Medium         651\n",
      "High           651\n",
      "Blockbuster    651\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unlabeled rows (revenue_tier = NaN): 6686\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create revenue_tier from LABELED rows only\n",
    "# ============================================================\n",
    "\n",
    "# Step 1: Identify labeled rows (revenue is not NaN)\n",
    "df_labeled = data_features_master[data_features_master[\"revenue\"].notna()].copy()\n",
    "print(f\"Labeled rows (revenue not NaN): {len(df_labeled)}\")\n",
    "print(f\"Unlabeled rows (revenue is NaN): {len(data_features_master) - len(df_labeled)}\")\n",
    "\n",
    "# Step 2: Compute quantile thresholds from labeled data ONLY\n",
    "thresholds = df_labeled[\"revenue\"].quantile([0.25, 0.50, 0.75])\n",
    "q25, q50, q75 = thresholds.iloc[0], thresholds.iloc[1], thresholds.iloc[2]\n",
    "\n",
    "print(f\"\\nRevenue quantile thresholds (from labeled data only):\")\n",
    "print(f\"  Q25 (Low/Medium boundary):       ${q25:,.0f}\")\n",
    "print(f\"  Q50 (Medium/High boundary):       ${q50:,.0f}\")\n",
    "print(f\"  Q75 (High/Blockbuster boundary):  ${q75:,.0f}\")\n",
    "\n",
    "# Step 3: Assign revenue_tier using defined bins\n",
    "bins = [-np.inf, q25, q50, q75, np.inf]\n",
    "labels_tier = [\"Low\", \"Medium\", \"High\", \"Blockbuster\"]\n",
    "\n",
    "# Apply pd.cut to the full revenue column — NaN revenues automatically get NaN tiers\n",
    "data_features_master[\"revenue_tier\"] = pd.cut(\n",
    "    data_features_master[\"revenue\"],\n",
    "    bins=bins,\n",
    "    labels=labels_tier\n",
    ")\n",
    "\n",
    "# Step 4: Store thresholds for reproducibility\n",
    "revenue_tier_thresholds = {\"Q25\": q25, \"Q50\": q50, \"Q75\": q75}\n",
    "print(f\"\\nRevenue tier distribution (labeled rows only):\")\n",
    "print(data_features_master[\"revenue_tier\"].value_counts())\n",
    "print(f\"\\nUnlabeled rows (revenue_tier = NaN): {data_features_master['revenue_tier'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74133572",
   "metadata": {},
   "source": [
    "## 14. Define Pre-Release Feature Columns\n",
    "\n",
    "Define the list of columns that constitute valid pre-release features. These will be used in all feature matrices for modeling. Post-release variables (popularity, vote_average, vote_count) and raw targets (revenue, budget) are explicitly excluded from feature matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99019e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-release feature columns (52):\n",
      "['runtime', 'director_popularity', 'actor1_popularity', 'actor2_popularity', 'actor3_popularity', 'actor4_popularity', 'actor5_popularity', 'cast_pop_mean', 'cast_pop_max', 'release_month', 'release_year', 'release_quarter', 'is_summer_release', 'is_holiday_release', 'star_count', 'cast_popularity_std', 'cast_gender_ratio', 'director_is_female', 'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', 'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western', 'num_genres', 'keyword_count', 'lang_en', 'lang_fr', 'lang_es', 'lang_ja', 'lang_de', 'lang_other', 'is_english', 'revenue_missing_flag', 'budget_missing_flag', 'has_budget', 'log_budget', 'has_overview', 'overview_length']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Define pre-release feature columns\n",
    "# ============================================================\n",
    "\n",
    "# Columns that must NOT be used as features when predicting revenue\n",
    "post_release_exclude = [\"popularity\", \"vote_average\", \"vote_count\"]\n",
    "target_exclude = [\"revenue\", \"budget\", \"revenue_tier\", \"revenue_missing_flag\"]\n",
    "# budget_missing_flag is a valid feature (it's known pre-release)\n",
    "# but raw budget is replaced by log_budget + has_budget\n",
    "\n",
    "# All pre-release feature columns\n",
    "all_master_cols = list(data_features_master.columns)\n",
    "non_feature_cols = post_release_exclude + [\"revenue\", \"budget\", \"revenue_tier\"]\n",
    "\n",
    "pre_release_features = [c for c in all_master_cols if c not in non_feature_cols]\n",
    "\n",
    "print(f\"Pre-release feature columns ({len(pre_release_features)}):\")\n",
    "print(pre_release_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288daa7b",
   "metadata": {},
   "source": [
    "## 15. Dataset Builder Functions\n",
    "\n",
    "Three functions to construct task-specific datasets from the master:\n",
    "\n",
    "1. **`build_supervised_dataset(target)`** — For supervised models (revenue or popularity)\n",
    "2. **`build_ssl_dataset()`** — For semi-supervised revenue classification (all rows, y_ssl = tier or -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19cd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset builder functions defined: build_supervised_dataset(), build_ssl_dataset()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Dataset builder: Supervised\n",
    "# ============================================================\n",
    "def build_supervised_dataset(master_df, target=\"revenue\"):\n",
    "    \"\"\"\n",
    "    Build a supervised dataset from the master.\n",
    "    \n",
    "    Parameters:\n",
    "        master_df: the master feature dataframe\n",
    "        target: \"revenue\" or \"popularity\"\n",
    "    \n",
    "    Returns:\n",
    "        X (features DataFrame), y (target Series)\n",
    "    \"\"\"\n",
    "    if target == \"revenue\":\n",
    "        # Only rows where revenue is not NaN\n",
    "        df_sub = master_df[master_df[\"revenue\"].notna()].copy()\n",
    "        y = df_sub[\"revenue\"].copy()\n",
    "        \n",
    "        # Exclude post-release + raw targets from features\n",
    "        exclude = [\"popularity\", \"vote_average\", \"vote_count\",\n",
    "                    \"revenue\", \"budget\", \"revenue_tier\"]\n",
    "        X = df_sub.drop(columns=[c for c in exclude if c in df_sub.columns])\n",
    "        \n",
    "    elif target == \"popularity\":\n",
    "        # Only rows where popularity is not NaN\n",
    "        df_sub = master_df[master_df[\"popularity\"].notna()].copy()\n",
    "        y = df_sub[\"popularity\"].copy()\n",
    "        \n",
    "        # Exclude revenue + other post-release from features\n",
    "        exclude = [\"popularity\", \"vote_average\", \"vote_count\",\n",
    "                    \"revenue\", \"budget\", \"revenue_tier\"]\n",
    "        X = df_sub.drop(columns=[c for c in exclude if c in df_sub.columns])\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown target: {target}. Use 'revenue' or 'popularity'.\")\n",
    "    \n",
    "    print(f\"Supervised dataset for '{target}':\")\n",
    "    print(f\"  X shape: {X.shape}\")\n",
    "    print(f\"  y shape: {y.shape}\")\n",
    "    print(f\"  Features: {list(X.columns)}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataset builder: Semi-Supervised (SSL) for Revenue\n",
    "# ============================================================\n",
    "def build_ssl_dataset(master_df):\n",
    "    \"\"\"\n",
    "    Build a semi-supervised dataset for revenue tier classification.\n",
    "    \n",
    "    - All rows included\n",
    "    - y_ssl = revenue_tier label (encoded as int) if revenue is not NaN\n",
    "    - y_ssl = -1 if revenue is NaN (unlabeled)\n",
    "    - No post-release features in X\n",
    "    \n",
    "    Returns:\n",
    "        X (features DataFrame), y_ssl (Series with int labels or -1)\n",
    "    \"\"\"\n",
    "    df_ssl = master_df.copy()\n",
    "    \n",
    "    # Use .cat.codes: pd.cut creates ordered Categorical where\n",
    "    # codes map to 0=Low, 1=Medium, 2=High, 3=Blockbuster, -1=NaN\n",
    "    # This avoids the fillna error on Categorical columns\n",
    "    df_ssl[\"y_ssl\"] = df_ssl[\"revenue_tier\"].cat.codes.astype(int)\n",
    "    \n",
    "    y_ssl = df_ssl[\"y_ssl\"].copy()\n",
    "    \n",
    "    # Exclude post-release + raw targets from features\n",
    "    exclude = [\"popularity\", \"vote_average\", \"vote_count\",\n",
    "                \"revenue\", \"budget\", \"revenue_tier\", \"y_ssl\"]\n",
    "    X = df_ssl.drop(columns=[c for c in exclude if c in df_ssl.columns])\n",
    "    \n",
    "    print(f\"SSL dataset for revenue tier:\")\n",
    "    print(f\"  X shape: {X.shape}\")\n",
    "    print(f\"  y_ssl shape: {y_ssl.shape}\")\n",
    "    print(f\"  Labeled:   {(y_ssl != -1).sum()}\")\n",
    "    print(f\"  Unlabeled: {(y_ssl == -1).sum()}\")\n",
    "    print(f\"  y_ssl distribution:\\n{y_ssl.value_counts().sort_index().to_dict()}\")\n",
    "    print(f\"  Features: {list(X.columns)}\")\n",
    "    return X, y_ssl\n",
    "\n",
    "\n",
    "print(\"Dataset builder functions defined: build_supervised_dataset(), build_ssl_dataset()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b84ab",
   "metadata": {},
   "source": [
    "## 16. Scaling Preparation for Graph-Based SSL\n",
    "\n",
    "LabelPropagation and LabelSpreading use distance-based kernels (RBF) and are sensitive to feature scales. A `StandardScaler` pipeline is prepared here. **Scaling must be applied after train/test split** to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b30542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling pipeline function defined: create_ssl_scaling_pipeline()\n",
      "Example: pipe = create_ssl_scaling_pipeline(LabelSpreading, kernel='rbf', gamma=20)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Scaling pipeline for graph-based SSL (LabelPropagation / LabelSpreading)\n",
    "# ============================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "\n",
    "def create_ssl_scaling_pipeline(model_class=LabelSpreading, **model_kwargs):\n",
    "    \"\"\"\n",
    "    Create a Pipeline with StandardScaler + SSL classifier.\n",
    "    \n",
    "    IMPORTANT: Apply this AFTER train/test split to prevent leakage.\n",
    "    The scaler fits only on training data.\n",
    "    \n",
    "    Usage:\n",
    "        pipe = create_ssl_scaling_pipeline(LabelSpreading, kernel='rbf', gamma=20)\n",
    "        pipe.fit(X_train, y_train_ssl)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ssl_model\", model_class(**model_kwargs))\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "print(\"Scaling pipeline function defined: create_ssl_scaling_pipeline()\")\n",
    "print(\"Example: pipe = create_ssl_scaling_pipeline(LabelSpreading, kernel='rbf', gamma=20)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432fa06",
   "metadata": {},
   "source": [
    "## 17. Dataset Validation Checks\n",
    "\n",
    "Before exporting, validate:\n",
    "- Labeled vs unlabeled observation counts\n",
    "- Revenue tier class distribution\n",
    "- Missing values per feature\n",
    "- Confirm no post-release columns in SSL feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef84bf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET VALIDATION\n",
      "============================================================\n",
      "\n",
      "1. Revenue observations:\n",
      "   Labeled (revenue known):   2604\n",
      "   Unlabeled (revenue NaN):   6686\n",
      "   Total:                     9290\n",
      "\n",
      "2. Revenue tier distribution:\n",
      "revenue_tier\n",
      "Low            651\n",
      "Medium         651\n",
      "High           651\n",
      "Blockbuster    651\n",
      "Name: count, dtype: int64\n",
      "   NaN (unlabeled): 6686\n",
      "\n",
      "3. Missing values per column (top 15):\n",
      "              count    pct\n",
      "revenue        6686  71.97\n",
      "revenue_tier   6686  71.97\n",
      "budget         6527  70.26\n",
      "\n",
      "4. SSL feature matrix leakage check:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot setitem on a Categorical with a new category (-1), set the categories first",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 4. Build SSL dataset and verify no post-release leakage\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m4. SSL feature matrix leakage check:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m X_ssl_check, y_ssl_check = \u001b[43mbuild_ssl_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_features_master\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m forbidden_in_ssl = [\u001b[33m\"\u001b[39m\u001b[33mpopularity\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvote_average\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvote_count\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrevenue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrevenue_tier\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     32\u001b[39m leakage_found = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m forbidden_in_ssl \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m X_ssl_check.columns]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mbuild_ssl_dataset\u001b[39m\u001b[34m(master_df)\u001b[39m\n\u001b[32m     63\u001b[39m tier_map = {\u001b[33m\"\u001b[39m\u001b[33mLow\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMedium\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBlockbuster\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m}\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Create y_ssl: mapped tier or -1 for unlabeled\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m df_ssl[\u001b[33m\"\u001b[39m\u001b[33my_ssl\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf_ssl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrevenue_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtier_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     68\u001b[39m y_ssl = df_ssl[\u001b[33m\"\u001b[39m\u001b[33my_ssl\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Exclude post-release + raw targets from features\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Majo\\TMDB-Movies-INSY-674\\.conda\\Lib\\site-packages\\pandas\\core\\generic.py:7086\u001b[39m, in \u001b[36mNDFrame.fillna\u001b[39m\u001b[34m(self, value, axis, inplace, limit)\u001b[39m\n\u001b[32m   7079\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7080\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   7081\u001b[39m             \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m parameter must be a scalar, dict \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7082\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor Series, but you passed a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   7083\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7084\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m7086\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mdict\u001b[39m, ABCSeries)):\n\u001b[32m   7089\u001b[39m     result = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Majo\\TMDB-Movies-INSY-674\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:458\u001b[39m, in \u001b[36mBaseBlockManager.fillna\u001b[39m\u001b[34m(self, value, limit, inplace)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    455\u001b[39m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[32m    456\u001b[39m     limit = libalgos.validate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit=limit)\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfillna\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Majo\\TMDB-Movies-INSY-674\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:442\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    440\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    445\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, [ax.view() \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axes])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Majo\\TMDB-Movies-INSY-674\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1909\u001b[39m, in \u001b[36mExtensionBlock.fillna\u001b[39m\u001b[34m(self, value, limit, inplace)\u001b[39m\n\u001b[32m   1906\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1907\u001b[39m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n\u001b[32m   1908\u001b[39m     refs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1909\u001b[39m     new_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1910\u001b[39m     \u001b[38;5;66;03m# issue the warning *after* retrying, in case the TypeError\u001b[39;00m\n\u001b[32m   1911\u001b[39m     \u001b[38;5;66;03m#  was caused by an invalid fill_value\u001b[39;00m\n\u001b[32m   1912\u001b[39m     warnings.warn(\n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# GH#53278\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExtensionArray.fillna added a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keyword in pandas \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1920\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1921\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Majo\\TMDB-Movies-INSY-674\\.conda\\Lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:368\u001b[39m, in \u001b[36mNDArrayBackedExtensionArray.fillna\u001b[39m\u001b[34m(self, value, limit, copy)\u001b[39m\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    367\u001b[39m         new_values = \u001b[38;5;28mself\u001b[39m[:]\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m = value\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;66;03m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_setitem_value(value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Majo\\TMDB-Movies-INSY-674\\.conda\\Lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:272\u001b[39m, in \u001b[36mNDArrayBackedExtensionArray.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot modify read-only array\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    271\u001b[39m key = check_array_indexer(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_setitem_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28mself\u001b[39m._ndarray[key] = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Majo\\TMDB-Movies-INSY-674\\.conda\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:1653\u001b[39m, in \u001b[36mCategorical._validate_setitem_value\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   1651\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._validate_listlike(value)\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1653\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Majo\\TMDB-Movies-INSY-674\\.conda\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:1678\u001b[39m, in \u001b[36mCategorical._validate_scalar\u001b[39m\u001b[34m(self, fill_value)\u001b[39m\n\u001b[32m   1676\u001b[39m     fill_value = \u001b[38;5;28mself\u001b[39m._unbox_scalar(fill_value)\n\u001b[32m   1677\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1678\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   1679\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot setitem on a Categorical with a new \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1680\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcategory (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfill_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m), set the categories first\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1681\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1682\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fill_value\n",
      "\u001b[31mTypeError\u001b[39m: Cannot setitem on a Categorical with a new category (-1), set the categories first"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Validation checks\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Labeled vs Unlabeled revenue observations\n",
    "n_labeled = data_features_master[\"revenue\"].notna().sum()\n",
    "n_unlabeled = data_features_master[\"revenue\"].isna().sum()\n",
    "print(f\"\\n1. Revenue observations:\")\n",
    "print(f\"   Labeled (revenue known):   {n_labeled}\")\n",
    "print(f\"   Unlabeled (revenue NaN):   {n_unlabeled}\")\n",
    "print(f\"   Total:                     {n_labeled + n_unlabeled}\")\n",
    "\n",
    "# 2. Revenue tier distribution\n",
    "print(f\"\\n2. Revenue tier distribution:\")\n",
    "print(data_features_master[\"revenue_tier\"].value_counts())\n",
    "print(f\"   NaN (unlabeled): {data_features_master['revenue_tier'].isna().sum()}\")\n",
    "\n",
    "# 3. Missing values per feature\n",
    "print(f\"\\n3. Missing values per column (top 15):\")\n",
    "missing = data_features_master.isnull().sum().sort_values(ascending=False)\n",
    "missing_pct = (missing / len(data_features_master) * 100).round(2)\n",
    "missing_report = pd.DataFrame({\"count\": missing, \"pct\": missing_pct})\n",
    "print(missing_report[missing_report[\"count\"] > 0].head(15))\n",
    "\n",
    "# 4. Build SSL dataset and verify no post-release leakage\n",
    "print(f\"\\n4. SSL feature matrix leakage check:\")\n",
    "X_ssl_check, y_ssl_check = build_ssl_dataset(data_features_master)\n",
    "forbidden_in_ssl = [\"popularity\", \"vote_average\", \"vote_count\", \"revenue\", \"revenue_tier\"]\n",
    "leakage_found = [c for c in forbidden_in_ssl if c in X_ssl_check.columns]\n",
    "if leakage_found:\n",
    "    print(f\"   WARNING: Post-release leakage detected: {leakage_found}\")\n",
    "else:\n",
    "    print(f\"   PASSED - No post-release columns in SSL feature matrix\")\n",
    "\n",
    "# 5. Supervised dataset check\n",
    "print(f\"\\n5. Supervised revenue dataset check:\")\n",
    "X_rev_check, y_rev_check = build_supervised_dataset(data_features_master, target=\"revenue\")\n",
    "leakage_rev = [c for c in forbidden_in_ssl if c in X_rev_check.columns]\n",
    "if leakage_rev:\n",
    "    print(f\"   WARNING: Leakage detected: {leakage_rev}\")\n",
    "else:\n",
    "    print(f\"   PASSED - No post-release columns in supervised revenue features\")\n",
    "\n",
    "print(f\"\\n6. Supervised popularity dataset check:\")\n",
    "X_pop_check, y_pop_check = build_supervised_dataset(data_features_master, target=\"popularity\")\n",
    "leakage_pop = [c for c in [\"popularity\", \"revenue\", \"revenue_tier\"] if c in X_pop_check.columns]\n",
    "if leakage_pop:\n",
    "    print(f\"   WARNING: Leakage detected: {leakage_pop}\")\n",
    "else:\n",
    "    print(f\"   PASSED - No target leakage in supervised popularity features\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"Revenue tier thresholds (for reproducibility):\")\n",
    "for k, v in revenue_tier_thresholds.items():\n",
    "    print(f\"  {k}: ${v:,.0f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43928fd",
   "metadata": {},
   "source": [
    "## 18. Export Clean Outputs\n",
    "\n",
    "Export four datasets:\n",
    "1. **data_features_master.csv** — neutral master (all rows, all features + raw targets)\n",
    "2. **data_supervised_revenue.csv** — labeled rows, pre-release features + revenue target\n",
    "3. **data_supervised_popularity.csv** — labeled rows, pre-release features + popularity target\n",
    "4. **data_ssl_revenue.csv** — all rows, pre-release features + y_ssl column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b32075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Export all datasets\n",
    "# ============================================================\n",
    "import os\n",
    "\n",
    "output_dir = \"../data\"\n",
    "\n",
    "# 1. Master dataset\n",
    "master_path = os.path.join(output_dir, \"data_features_master.csv\")\n",
    "data_features_master.to_csv(master_path, index=False)\n",
    "print(f\"[1/4] Saved: {master_path}  shape={data_features_master.shape}\")\n",
    "\n",
    "# 2. Supervised revenue dataset\n",
    "X_rev, y_rev = build_supervised_dataset(data_features_master, target=\"revenue\")\n",
    "sup_rev = X_rev.copy()\n",
    "sup_rev[\"revenue\"] = y_rev.values\n",
    "sup_rev_path = os.path.join(output_dir, \"data_supervised_revenue.csv\")\n",
    "sup_rev.to_csv(sup_rev_path, index=False)\n",
    "print(f\"[2/4] Saved: {sup_rev_path}  shape={sup_rev.shape}\")\n",
    "\n",
    "# 3. Supervised popularity dataset\n",
    "X_pop, y_pop = build_supervised_dataset(data_features_master, target=\"popularity\")\n",
    "sup_pop = X_pop.copy()\n",
    "sup_pop[\"popularity\"] = y_pop.values\n",
    "sup_pop_path = os.path.join(output_dir, \"data_supervised_popularity.csv\")\n",
    "sup_pop.to_csv(sup_pop_path, index=False)\n",
    "print(f\"[3/4] Saved: {sup_pop_path}  shape={sup_pop.shape}\")\n",
    "\n",
    "# 4. SSL revenue dataset\n",
    "X_ssl, y_ssl = build_ssl_dataset(data_features_master)\n",
    "ssl_rev = X_ssl.copy()\n",
    "ssl_rev[\"y_ssl\"] = y_ssl.values\n",
    "ssl_rev_path = os.path.join(output_dir, \"data_ssl_revenue.csv\")\n",
    "ssl_rev.to_csv(ssl_rev_path, index=False)\n",
    "print(f\"[4/4] Saved: {ssl_rev_path}  shape={ssl_rev.shape}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL EXPORTS COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a05ca",
   "metadata": {},
   "source": [
    "## Final System Structure\n",
    "\n",
    "| Component | Description |\n",
    "|---|---|\n",
    "| **data_features_master.csv** | Neutral master dataset — all rows, all pre-release features, raw targets, missing flags |\n",
    "| **data_supervised_revenue.csv** | Labeled rows only, pre-release features + revenue |\n",
    "| **data_supervised_popularity.csv** | Labeled rows only, pre-release features + popularity |\n",
    "| **data_ssl_revenue.csv** | All rows, pre-release features + y_ssl (tier label or -1) |\n",
    "| **build_supervised_dataset()** | Function to construct supervised X, y for revenue or popularity |\n",
    "| **build_ssl_dataset()** | Function to construct SSL X, y_ssl with -1 for unlabeled |\n",
    "| **create_ssl_scaling_pipeline()** | StandardScaler + SSL model pipeline (apply after split) |\n",
    "\n",
    "**Guarantees:**\n",
    "- No target leakage (post-release variables excluded from feature matrices)\n",
    "- Revenue tiers computed only from labeled observations\n",
    "- Zero values in budget/revenue corrected to NaN with flags\n",
    "- All pre-release variables preserved\n",
    "- Missing revenue rows retained as unlabeled for SSL\n",
    "- Reproducible quantile thresholds documented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
