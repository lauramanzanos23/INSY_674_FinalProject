{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdb9781",
   "metadata": {},
   "source": [
    "# Feature Engineering — TMDB Movie Revenue & Popularity Prediction\n",
    "\n",
    "**Purpose:** Transform raw TMDB movie data into a clean, target-agnostic master feature dataset that supports both supervised and semi-supervised modeling for revenue and popularity prediction.\n",
    "\n",
    "**Key Principles:**\n",
    "- **Target-agnostic master dataset:** We create `data_features_master` containing ALL pre-release features plus raw revenue, popularity, and budget — without filtering for any specific target.\n",
    "- **Zero correction:** Budget and revenue values of 0 are treated as missing (replaced with NaN) and tracked with binary flags.\n",
    "- **No data leakage:** Post-release metrics (vote_average, vote_count) are excluded from feature matrices at modeling time, not deleted from the master.\n",
    "- **Semi-supervised ready:** Rows with missing revenue remain in the dataset as unlabeled observations (y = -1) for SSL classifiers.\n",
    "- **Revenue tiers:** Computed only from labeled (non-NaN revenue) observations using quantile-based binning.\n",
    "\n",
    "**Feature Categories:**\n",
    "1. Talent Features (cast & director signals)\n",
    "2. Content Features (genres, keywords, language)\n",
    "3. Temporal Features (release timing & seasonality)\n",
    "4. Production Features (budget, runtime)\n",
    "\n",
    "**Output Datasets:**\n",
    "- `data_features_master.csv` — neutral master (all rows, all features, raw targets)\n",
    "- `data_supervised_revenue.csv` — labeled rows only, no post-release features\n",
    "- `data_supervised_popularity.csv` — labeled rows only, no revenue features\n",
    "- `data_ssl_revenue.csv` — all rows with y_ssl column for semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c2faea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd09b5",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load the raw TMDB dataset and drop the unnamed index column carried over from the CSV export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ec0c2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9290, 51)\n",
      "Columns: ['movie_id', 'title', 'release_date', 'runtime', 'original_language', 'popularity', 'vote_average', 'vote_count', 'budget', 'revenue', 'status', 'overview', 'genres', 'keywords', 'director_id', 'director_name', 'director_gender', 'director_popularity', 'director_department', 'actor1_id', 'actor1_name', 'actor1_character', 'actor1_gender', 'actor1_popularity', 'actor1_department', 'actor2_id', 'actor2_name', 'actor2_character', 'actor2_gender', 'actor2_popularity', 'actor2_department', 'actor3_id', 'actor3_name', 'actor3_character', 'actor3_gender', 'actor3_popularity', 'actor3_department', 'actor4_id', 'actor4_name', 'actor4_character', 'actor4_gender', 'actor4_popularity', 'actor4_department', 'actor5_id', 'actor5_name', 'actor5_character', 'actor5_gender', 'actor5_popularity', 'actor5_department', 'cast_pop_mean', 'cast_pop_max']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load raw data\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"../data/movies_2010_2025.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2d57e",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Reusable parsing utilities inherited from the EDA phase. The `safe_parse_list` function handles the genres and keywords columns, which are stored as string representations of Python lists in the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54e314a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Helper: safely parse stringified lists from CSV\n",
    "# ============================================================\n",
    "def safe_parse_list(x):\n",
    "    \"\"\"\n",
    "    Convert stringified lists (e.g., \"['Action', 'Drama']\") back into\n",
    "    actual Python lists. Handles NaN, empty strings, and edge cases.\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, float) and pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        if x == \"\" or x == \"[]\":\n",
    "            return []\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c35d6c",
   "metadata": {},
   "source": [
    "## 3. Column Classification — Pre-Release vs Post-Release\n",
    "\n",
    "We classify every column as pre-release (available before the movie opens) or post-release (only known after release). This classification drives all downstream dataset construction.\n",
    "\n",
    "**Pre-release features (valid for modeling):**\n",
    "- Temporal: release_year, release_month, release_quarter, is_summer_release, is_holiday_release\n",
    "- Cast: actor1-5 popularity, cast_pop_mean, cast_pop_max, star_count, cast_popularity_std, cast_gender_ratio\n",
    "- Director: director_popularity, director_is_female\n",
    "- Content: genre_* (one-hot), num_genres, keyword_count, lang_* encodings, is_english\n",
    "- Production: runtime, has_budget, log_budget\n",
    "- Text signal: has_overview, overview_length\n",
    "\n",
    "**Post-release variables (kept in master, excluded from feature matrices):**\n",
    "- popularity, vote_average, vote_count\n",
    "\n",
    "**Raw target variables (kept in master for target construction):**\n",
    "- revenue, budget (raw values preserved alongside engineered versions)\n",
    "\n",
    "**Identifier / non-predictive columns (dropped from master):**\n",
    "- movie_id, title, status, overview, all name/character/department/ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99226812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (popularity) shape: (9290,)\n",
      "Target stats:\n",
      "count    9290.000000\n",
      "mean        5.788687\n",
      "std         7.689172\n",
      "min         2.414700\n",
      "25%         3.885000\n",
      "50%         4.501300\n",
      "75%         5.628275\n",
      "max       378.004500\n",
      "Name: popularity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Classify columns: post-release metrics to keep in master\n",
    "# but exclude from feature matrices during modeling\n",
    "# ============================================================\n",
    "post_release_cols = [\"popularity\", \"vote_average\", \"vote_count\"]\n",
    "raw_target_cols = [\"revenue\", \"budget\"]\n",
    "\n",
    "print(\"Post-release columns (kept in master, excluded from features):\", post_release_cols)\n",
    "print(\"Raw target columns (kept in master for target construction):\", raw_target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dddc7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns excluded: 31\n",
      "Excluded: ['popularity', 'vote_average', 'vote_count', 'revenue', 'movie_id', 'title', 'status', 'overview', 'director_id', 'director_name', 'director_department', 'actor1_id', 'actor1_name', 'actor1_character', 'actor1_department', 'actor2_id', 'actor2_name', 'actor2_character', 'actor2_department', 'actor3_id', 'actor3_name', 'actor3_character', 'actor3_department', 'actor4_id', 'actor4_name', 'actor4_character', 'actor4_department', 'actor5_id', 'actor5_name', 'actor5_character', 'actor5_department']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Define columns to exclude from the MASTER dataset entirely\n",
    "# (identifiers, free text, high-cardinality names, near-zero variance departments)\n",
    "# ============================================================\n",
    "id_cols = [\"movie_id\", \"title\"]\n",
    "\n",
    "non_predictive_cols = [\n",
    "    \"status\", \"overview\",\n",
    "    \"director_id\", \"director_name\", \"director_department\",\n",
    "    \"actor1_id\", \"actor1_name\", \"actor1_character\", \"actor1_department\",\n",
    "    \"actor2_id\", \"actor2_name\", \"actor2_character\", \"actor2_department\",\n",
    "    \"actor3_id\", \"actor3_name\", \"actor3_character\", \"actor3_department\",\n",
    "    \"actor4_id\", \"actor4_name\", \"actor4_character\", \"actor4_department\",\n",
    "    \"actor5_id\", \"actor5_name\", \"actor5_character\", \"actor5_department\",\n",
    "]\n",
    "\n",
    "# These are dropped from the master dataset entirely\n",
    "all_excluded_from_master = id_cols + non_predictive_cols\n",
    "\n",
    "print(f\"Total columns excluded from master: {len(all_excluded_from_master)}\")\n",
    "print(f\"Excluded: {all_excluded_from_master}\")\n",
    "print(f\"\\nNOTE: revenue, budget, popularity, vote_average, vote_count are KEPT in the master.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba9375",
   "metadata": {},
   "source": [
    "## 4. Parse List Columns\n",
    "\n",
    "The `genres` and `keywords` columns are stored as stringified Python lists in the CSV. We parse them into actual lists before engineering features from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f1c7667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample genres: ['Action', 'Science Fiction', 'Adventure']\n",
      "Sample keywords: ['rescue', 'mission', 'dreams', 'airplane', 'paris, france', 'virtual reality', 'kidnapping', 'philosophy', 'spy', 'allegory', 'manipulation', 'car crash', 'heist', 'memory', 'architecture', 'los angeles, california', 'death', 'dream world', 'subconscious', 'dream']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Parse genres and keywords from strings to lists\n",
    "# ============================================================\n",
    "df[\"genres\"] = df[\"genres\"].apply(safe_parse_list)\n",
    "df[\"keywords\"] = df[\"keywords\"].apply(safe_parse_list)\n",
    "\n",
    "# Quick verification\n",
    "print(\"Sample genres:\", df[\"genres\"].iloc[0])\n",
    "print(\"Sample keywords:\", df[\"keywords\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a53c4",
   "metadata": {},
   "source": [
    "## 5. Temporal Features — Release Timing & Seasonality\n",
    "\n",
    "Movie success is heavily influenced by **when** it is released. Summer blockbuster season, holiday releases, and award-season timing are well-known industry patterns.\n",
    "\n",
    "**Features engineered:**\n",
    "- `release_month` — captures monthly seasonality (e.g., June/July for summer blockbusters, Nov/Dec for awards and holidays)\n",
    "- `release_year` — captures long-term industry trends (e.g., streaming era shifts)\n",
    "- `release_quarter` — a coarser seasonal signal (Q1-Q4)\n",
    "- `is_summer_release` — binary flag for the peak blockbuster window (May-July)\n",
    "- `is_holiday_release` — binary flag for the holiday corridor (November-December)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad4ccc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal features created:\n",
      "       release_month  release_year  release_quarter  is_summer_release  \\\n",
      "count    9290.000000   9290.000000      9290.000000        9290.000000   \n",
      "mean        6.752530   2017.456512         2.587406           0.218837   \n",
      "std         3.463668      4.623364         1.136100           0.413480   \n",
      "min         1.000000   2010.000000         1.000000           0.000000   \n",
      "25%         4.000000   2013.000000         2.000000           0.000000   \n",
      "50%         7.000000   2017.000000         3.000000           0.000000   \n",
      "75%        10.000000   2021.000000         4.000000           0.000000   \n",
      "max        12.000000   2025.000000         4.000000           1.000000   \n",
      "\n",
      "       is_holiday_release  \n",
      "count         9290.000000  \n",
      "mean             0.164155  \n",
      "std              0.370436  \n",
      "min              0.000000  \n",
      "25%              0.000000  \n",
      "50%              0.000000  \n",
      "75%              0.000000  \n",
      "max              1.000000  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Temporal features from release_date\n",
    "# ============================================================\n",
    "df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "\n",
    "# Month and year\n",
    "df[\"release_month\"] = df[\"release_date\"].dt.month\n",
    "df[\"release_year\"] = df[\"release_date\"].dt.year\n",
    "\n",
    "# Quarter (1-4)\n",
    "df[\"release_quarter\"] = df[\"release_date\"].dt.quarter\n",
    "\n",
    "# Summer release: May (5), June (6), July (7)\n",
    "df[\"is_summer_release\"] = df[\"release_month\"].isin([5, 6, 7]).astype(int)\n",
    "\n",
    "# Holiday release: November (11), December (12)\n",
    "df[\"is_holiday_release\"] = df[\"release_month\"].isin([11, 12]).astype(int)\n",
    "\n",
    "# Handle the 1 missing release_date - fill temporal features with median\n",
    "for col in [\"release_month\", \"release_year\", \"release_quarter\"]:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "print(\"Temporal features created:\")\n",
    "print(df[[\"release_month\", \"release_year\", \"release_quarter\",\n",
    "          \"is_summer_release\", \"is_holiday_release\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b9061",
   "metadata": {},
   "source": [
    "## 6. Talent Features — Cast & Director Signals\n",
    "\n",
    "The star power of a film's cast and director is one of the strongest pre-release indicators of audience interest. The dataset already provides individual actor popularities (actor1-5) and aggregated stats (`cast_pop_mean`, `cast_pop_max`). We engineer additional features to capture richer talent signals.\n",
    "\n",
    "**Features engineered:**\n",
    "- `director_popularity` — already exists in the data, retained as-is\n",
    "- `director_is_female` — binary flag (TMDB gender encoding: 1 = Female, 2 = Male)\n",
    "- `star_count` — number of actors (out of top 5 billed) whose popularity exceeds the 75th percentile across all actors; captures how many recognizable names are attached\n",
    "- `cast_popularity_std` — standard deviation of top 5 actors' popularities; high std = one big name + unknowns, low std = balanced ensemble\n",
    "- `cast_gender_ratio` — proportion of female actors in the top 5 billed cast\n",
    "- `cast_pop_mean`, `cast_pop_max` — already exist, retained as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5981b1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star threshold (75th percentile of non-zero actor popularity): 2.9868\n",
      "\n",
      "Talent features summary:\n",
      "        star_count  cast_popularity_std  cast_gender_ratio  \\\n",
      "count  9290.000000          9290.000000        9290.000000   \n",
      "mean      1.147578             1.260020           0.412983   \n",
      "std       1.364494             1.767775           0.259384   \n",
      "min       0.000000             0.000000           0.000000   \n",
      "25%       0.000000             0.576811           0.200000   \n",
      "50%       1.000000             1.017833           0.400000   \n",
      "75%       2.000000             1.516547           0.600000   \n",
      "max       5.000000            84.167164           1.000000   \n",
      "\n",
      "       director_is_female  director_popularity  cast_pop_mean  cast_pop_max  \n",
      "count         9290.000000          9290.000000    9290.000000   9290.000000  \n",
      "mean             0.116685             1.209358       2.023336      4.085244  \n",
      "std              0.321061             1.361564       1.876921      4.903623  \n",
      "min              0.000000             0.000000       0.000000      0.000000  \n",
      "25%              0.000000             0.248600       0.836880      1.985875  \n",
      "50%              0.000000             0.656450       1.553430      3.254900  \n",
      "75%              0.000000             1.745450       2.775495      4.993100  \n",
      "max              1.000000            20.877800      56.784000    224.150000  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Talent features\n",
    "# ============================================================\n",
    "\n",
    "# --- Actor popularity columns ---\n",
    "actor_pop_cols = [f\"actor{i}_popularity\" for i in range(1, 6)]\n",
    "actor_gender_cols = [f\"actor{i}_gender\" for i in range(1, 6)]\n",
    "\n",
    "# --- Star count ---\n",
    "# Define \"star\" threshold as 75th percentile of all non-zero actor popularities\n",
    "all_actor_pops = df[actor_pop_cols].values.flatten()\n",
    "all_actor_pops_nonzero = all_actor_pops[all_actor_pops > 0]\n",
    "star_threshold = np.percentile(all_actor_pops_nonzero, 75)\n",
    "print(f\"Star threshold (75th percentile of non-zero actor popularity): {star_threshold:.4f}\")\n",
    "\n",
    "# Count how many of the 5 actors exceed the star threshold per movie\n",
    "df[\"star_count\"] = (df[actor_pop_cols] > star_threshold).sum(axis=1)\n",
    "\n",
    "# --- Cast popularity standard deviation ---\n",
    "# Measures whether the cast is balanced or relies on a single star\n",
    "df[\"cast_popularity_std\"] = df[actor_pop_cols].apply(\n",
    "    lambda row: np.std([x for x in row if x > 0]) if any(x > 0 for x in row) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- Cast gender ratio (proportion female) ---\n",
    "# TMDB gender encoding: 1 = Female, 2 = Male, 0 = Unknown/Not set\n",
    "def calc_female_ratio(row):\n",
    "    known = [g for g in row if g in (1.0, 2.0)]\n",
    "    if len(known) == 0:\n",
    "        return 0.5  # default to balanced when unknown\n",
    "    return sum(1 for g in known if g == 1.0) / len(known)\n",
    "\n",
    "df[\"cast_gender_ratio\"] = df[actor_gender_cols].apply(calc_female_ratio, axis=1)\n",
    "\n",
    "# --- Director is female ---\n",
    "df[\"director_is_female\"] = (df[\"director_gender\"] == 1.0).astype(int)\n",
    "\n",
    "print(\"\\nTalent features summary:\")\n",
    "print(df[[\"star_count\", \"cast_popularity_std\", \"cast_gender_ratio\",\n",
    "          \"director_is_female\", \"director_popularity\",\n",
    "          \"cast_pop_mean\", \"cast_pop_max\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf239bf",
   "metadata": {},
   "source": [
    "## 7. Content Features — Genre Encoding\n",
    "\n",
    "Genres are a core signal for audience interest. Since a movie can belong to multiple genres, we use **multi-hot encoding** — each genre becomes a binary column (1 if the movie belongs to that genre, 0 otherwise).\n",
    "\n",
    "We also create `num_genres` to capture the breadth of a movie's genre classification. Movies spanning many genres may have broader audience appeal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc1eeb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique genres found: 19\n",
      "Genres: ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western']\n",
      "\n",
      "Genre feature columns created: 19 binary + 1 count\n",
      "num_genres distribution:\n",
      "count    9290.000000\n",
      "mean        1.988482\n",
      "std         1.108486\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         3.000000\n",
      "max         8.000000\n",
      "Name: num_genres, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Multi-hot encode genres\n",
    "# ============================================================\n",
    "\n",
    "# Get all unique genres across the dataset\n",
    "all_genres = sorted(set(g for genres_list in df[\"genres\"] for g in genres_list))\n",
    "print(f\"Total unique genres found: {len(all_genres)}\")\n",
    "print(f\"Genres: {all_genres}\")\n",
    "\n",
    "# Create binary columns for each genre\n",
    "for genre in all_genres:\n",
    "    df[f\"genre_{genre}\"] = df[\"genres\"].apply(lambda x, g=genre: 1 if g in x else 0)\n",
    "\n",
    "# Number of genres per movie\n",
    "df[\"num_genres\"] = df[\"genres\"].apply(len)\n",
    "\n",
    "print(f\"\\nGenre feature columns created: {len(all_genres)} binary + 1 count\")\n",
    "print(f\"num_genres distribution:\\n{df['num_genres'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34114962",
   "metadata": {},
   "source": [
    "## 8. Content Features — Keyword Count\n",
    "\n",
    "Rather than encoding individual keywords (which would create thousands of extremely sparse columns), we use the **keyword count** as a proxy for how richly tagged a movie is. Movies with more keywords tend to have more developed marketing and metadata, which itself correlates with production scale and audience reach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "324684e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword_count distribution:\n",
      "count    9290.000000\n",
      "mean        5.189020\n",
      "std         7.172168\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         2.000000\n",
      "75%         8.000000\n",
      "max       101.000000\n",
      "Name: keyword_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Keyword count\n",
    "# ============================================================\n",
    "df[\"keyword_count\"] = df[\"keywords\"].apply(len)\n",
    "\n",
    "print(\"keyword_count distribution:\")\n",
    "print(df[\"keyword_count\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c3f1f",
   "metadata": {},
   "source": [
    "## 9. Content Features — Original Language Encoding\n",
    "\n",
    "The EDA showed that English (`en`) dominates the dataset, with a long tail of other languages. We use a **top-K encoding** strategy:\n",
    "\n",
    "- The top 5 most frequent languages each get their own binary column.\n",
    "- All remaining languages are grouped into `lang_other`.\n",
    "- A simple `is_english` flag captures the most important language split for global popularity prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cd14201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 languages: ['en', 'fr', 'es', 'ja', 'de']\n",
      "\n",
      "is_english distribution:\n",
      "is_english\n",
      "1    5748\n",
      "0    3542\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Language encoding (top-K + is_english flag)\n",
    "# ============================================================\n",
    "\n",
    "# Identify top 5 languages by frequency\n",
    "top_languages = df[\"original_language\"].value_counts().head(5).index.tolist()\n",
    "print(f\"Top 5 languages: {top_languages}\")\n",
    "\n",
    "# Create binary column for each top language\n",
    "for lang in top_languages:\n",
    "    df[f\"lang_{lang}\"] = (df[\"original_language\"] == lang).astype(int)\n",
    "\n",
    "# Catch-all for less common languages\n",
    "df[\"lang_other\"] = (~df[\"original_language\"].isin(top_languages)).astype(int)\n",
    "\n",
    "# Simple is_english flag\n",
    "df[\"is_english\"] = (df[\"original_language\"] == \"en\").astype(int)\n",
    "\n",
    "print(f\"\\nis_english distribution:\\n{df['is_english'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a86d94",
   "metadata": {},
   "source": [
    "## 10. Production Features — Budget, Revenue Zero Correction & Runtime\n",
    "\n",
    "**Zero Correction:** In TMDB, `budget = 0` and `revenue = 0` mean \"not reported\", not truly $0. We:\n",
    "1. Replace `budget == 0` → `NaN` and `revenue == 0` → `NaN`\n",
    "2. Create `budget_missing_flag` and `revenue_missing_flag` (1 = missing, 0 = present)\n",
    "3. **Do NOT drop rows** with missing revenue — these define unlabeled observations for semi-supervised learning\n",
    "\n",
    "**Budget features:**\n",
    "- `has_budget` — binary flag (1 if budget is known)\n",
    "- `log_budget` — log1p transform (0 for missing budgets)\n",
    "- `budget_missing_flag` — 1 if budget was 0/NaN\n",
    "\n",
    "**Revenue handling:**\n",
    "- `revenue_missing_flag` — 1 if revenue was 0/NaN\n",
    "- Raw `revenue` is preserved in the master for target construction\n",
    "\n",
    "**Runtime:** Retained as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a7c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget features:\n",
      "  has_budget distribution: {0: 6527, 1: 2763}\n",
      "  log_budget stats (where budget > 0):\n",
      "count    2763.000000\n",
      "mean       15.833550\n",
      "std         3.021456\n",
      "min         0.693147\n",
      "25%        14.978662\n",
      "50%        16.705882\n",
      "75%        17.727534\n",
      "max        20.009712\n",
      "Name: log_budget, dtype: float64\n",
      "\n",
      "Runtime stats:\n",
      "count    9290.000000\n",
      "mean       81.390635\n",
      "std        44.067500\n",
      "min         0.000000\n",
      "25%        67.000000\n",
      "50%        92.000000\n",
      "75%       107.000000\n",
      "max       950.000000\n",
      "Name: runtime, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Production features: Budget & Revenue zero correction, Runtime\n",
    "# ============================================================\n",
    "\n",
    "# --- Revenue: replace 0 with NaN ---\n",
    "revenue_zero_count = (df[\"revenue\"] == 0).sum()\n",
    "df[\"revenue\"] = df[\"revenue\"].replace(0, np.nan)\n",
    "df[\"revenue_missing_flag\"] = df[\"revenue\"].isna().astype(int)\n",
    "print(f\"Revenue: {revenue_zero_count} zeros replaced with NaN\")\n",
    "print(f\"revenue_missing_flag distribution:\\n{df['revenue_missing_flag'].value_counts().to_dict()}\")\n",
    "\n",
    "# --- Budget: replace 0 with NaN ---\n",
    "budget_zero_count = (df[\"budget\"] == 0).sum()\n",
    "df[\"budget\"] = df[\"budget\"].replace(0, np.nan)\n",
    "df[\"budget_missing_flag\"] = df[\"budget\"].isna().astype(int)\n",
    "print(f\"\\nBudget: {budget_zero_count} zeros replaced with NaN\")\n",
    "print(f\"budget_missing_flag distribution:\\n{df['budget_missing_flag'].value_counts().to_dict()}\")\n",
    "\n",
    "# --- Budget engineered features ---\n",
    "df[\"has_budget\"] = (df[\"budget\"].notna()).astype(int)\n",
    "df[\"log_budget\"] = np.log1p(df[\"budget\"].fillna(0))\n",
    "\n",
    "print(f\"\\nhas_budget distribution: {df['has_budget'].value_counts().to_dict()}\")\n",
    "print(f\"log_budget stats (where budget known):\")\n",
    "print(df.loc[df[\"budget\"].notna(), \"log_budget\"].describe())\n",
    "\n",
    "# --- Runtime ---\n",
    "print(f\"\\nRuntime stats:\\n{df['runtime'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e1cec",
   "metadata": {},
   "source": [
    "## 11. Text Signal — Overview Availability\n",
    "\n",
    "The movie overview (synopsis) is free text that would require NLP to fully exploit. For this pipeline, we extract a simple but meaningful signal: **whether an overview exists and how long it is**. Movies with longer, more detailed overviews tend to have more developed marketing and distribution — a lightweight proxy for production effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6f93234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview features:\n",
      "  has_overview: {1: 9089, 0: 201}\n",
      "  overview_length stats:\n",
      "count    9290.000000\n",
      "mean      259.595048\n",
      "std       164.951892\n",
      "min         0.000000\n",
      "25%       146.000000\n",
      "50%       220.000000\n",
      "75%       339.000000\n",
      "max       999.000000\n",
      "Name: overview_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Overview-based features\n",
    "# ============================================================\n",
    "\n",
    "# Whether the movie has an overview at all\n",
    "df[\"has_overview\"] = df[\"overview\"].notna().astype(int)\n",
    "\n",
    "# Length of overview (character count)\n",
    "df[\"overview_length\"] = df[\"overview\"].fillna(\"\").apply(len)\n",
    "\n",
    "print(\"Overview features:\")\n",
    "print(f\"  has_overview: {df['has_overview'].value_counts().to_dict()}\")\n",
    "print(f\"  overview_length stats:\\n{df['overview_length'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed95812",
   "metadata": {},
   "source": [
    "## 12. Assemble Neutral Master Feature Dataset\n",
    "\n",
    "Create `data_features_master` — a target-agnostic dataset containing:\n",
    "- All pre-release engineered features\n",
    "- Raw revenue and raw popularity (for target construction)\n",
    "- Raw budget (preserved alongside log_budget and has_budget)\n",
    "- Missing flags (revenue_missing_flag, budget_missing_flag)\n",
    "- Post-release metrics (vote_average, vote_count) — kept in master, excluded at modeling time\n",
    "\n",
    "**No rows are dropped. No target-specific filtering.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23b999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (9290, 50)\n",
      "\n",
      "Feature columns (50):\n",
      "['runtime', 'director_popularity', 'actor1_popularity', 'actor2_popularity', 'actor3_popularity', 'actor4_popularity', 'actor5_popularity', 'cast_pop_mean', 'cast_pop_max', 'release_month', 'release_year', 'release_quarter', 'is_summer_release', 'is_holiday_release', 'star_count', 'cast_popularity_std', 'cast_gender_ratio', 'director_is_female', 'genre_Action', 'genre_Adventure', 'genre_Animation', 'genre_Comedy', 'genre_Crime', 'genre_Documentary', 'genre_Drama', 'genre_Family', 'genre_Fantasy', 'genre_History', 'genre_Horror', 'genre_Music', 'genre_Mystery', 'genre_Romance', 'genre_Science Fiction', 'genre_TV Movie', 'genre_Thriller', 'genre_War', 'genre_Western', 'num_genres', 'keyword_count', 'lang_en', 'lang_fr', 'lang_es', 'lang_ja', 'lang_de', 'lang_other', 'is_english', 'has_budget', 'log_budget', 'has_overview', 'overview_length']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Assemble the neutral master feature dataset\n",
    "# ============================================================\n",
    "\n",
    "# Drop only non-predictive/identifier columns and intermediate raw columns\n",
    "cols_to_drop_from_master = (\n",
    "    all_excluded_from_master\n",
    "    + [\"release_date\", \"original_language\", \"genres\", \"keywords\",\n",
    "       \"director_gender\",                             # replaced by director_is_female\n",
    "       \"actor1_gender\", \"actor2_gender\", \"actor3_gender\",\n",
    "       \"actor4_gender\", \"actor5_gender\",              # replaced by cast_gender_ratio\n",
    "       ]\n",
    ")\n",
    "\n",
    "# Only drop columns that actually exist\n",
    "cols_to_drop_existing = [c for c in cols_to_drop_from_master if c in df.columns]\n",
    "\n",
    "data_features_master = df.drop(columns=cols_to_drop_existing)\n",
    "\n",
    "print(f\"Master dataset shape: {data_features_master.shape}\")\n",
    "print(f\"\\nAll columns ({len(data_features_master.columns)}):\")\n",
    "print(list(data_features_master.columns))\n",
    "print(f\"\\n--- Confirming key columns are present ---\")\n",
    "for col in [\"revenue\", \"popularity\", \"budget\", \"vote_average\", \"vote_count\",\n",
    "            \"revenue_missing_flag\", \"budget_missing_flag\"]:\n",
    "    present = col in data_features_master.columns\n",
    "    print(f\"  {col}: {'YES' if present else 'MISSING!'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b3eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage check PASSED - no target or post-release variables in feature matrix.\n",
      "Data type check PASSED - all features are numeric.\n"
     ]
    }
   ],
   "source": [
    "## 13. Create Revenue Tier\n",
    "\n",
    "Revenue tiers are computed **only from rows where revenue is not NaN** (labeled observations). Quantile thresholds are calculated exclusively from labeled data.\n",
    "\n",
    "**Tiers:** Low, Medium, High, Blockbuster (based on quartiles)\n",
    "**Unlabeled rows:** revenue_tier = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Create revenue_tier from LABELED rows only\n",
    "# ============================================================\n",
    "\n",
    "# Step 1: Identify labeled rows (revenue is not NaN)\n",
    "df_labeled = data_features_master[data_features_master[\"revenue\"].notna()].copy()\n",
    "print(f\"Labeled rows (revenue not NaN): {len(df_labeled)}\")\n",
    "print(f\"Unlabeled rows (revenue is NaN): {len(data_features_master) - len(df_labeled)}\")\n",
    "\n",
    "# Step 2: Compute quantile thresholds from labeled data ONLY\n",
    "thresholds = df_labeled[\"revenue\"].quantile([0.25, 0.50, 0.75])\n",
    "q25, q50, q75 = thresholds.iloc[0], thresholds.iloc[1], thresholds.iloc[2]\n",
    "\n",
    "print(f\"\\nRevenue quantile thresholds (from labeled data only):\")\n",
    "print(f\"  Q25 (Low/Medium boundary):       ${q25:,.0f}\")\n",
    "print(f\"  Q50 (Medium/High boundary):       ${q50:,.0f}\")\n",
    "print(f\"  Q75 (High/Blockbuster boundary):  ${q75:,.0f}\")\n",
    "\n",
    "# Step 3: Assign revenue_tier using defined bins\n",
    "bins = [-np.inf, q25, q50, q75, np.inf]\n",
    "labels_tier = [\"Low\", \"Medium\", \"High\", \"Blockbuster\"]\n",
    "\n",
    "# Initialize as NaN for all rows\n",
    "data_features_master[\"revenue_tier\"] = np.nan\n",
    "\n",
    "# Assign tiers only to labeled rows\n",
    "labeled_idx = data_features_master[\"revenue\"].notna()\n",
    "data_features_master.loc[labeled_idx, \"revenue_tier\"] = pd.cut(\n",
    "    data_features_master.loc[labeled_idx, \"revenue\"],\n",
    "    bins=bins,\n",
    "    labels=labels_tier\n",
    ")\n",
    "\n",
    "# Step 4: Store thresholds for reproducibility\n",
    "revenue_tier_thresholds = {\"Q25\": q25, \"Q50\": q50, \"Q75\": q75}\n",
    "print(f\"\\nRevenue tier distribution (labeled rows only):\")\n",
    "print(data_features_master[\"revenue_tier\"].value_counts())\n",
    "print(f\"\\nUnlabeled rows (revenue_tier = NaN): {data_features_master['revenue_tier'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74133572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE ENGINEERING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Rows:     9290\n",
      "Features: 50\n",
      "Target:   popularity (9290 values)\n",
      "\n",
      "--- Missing values ---\n",
      "None - all features fully populated.\n",
      "\n",
      "--- Data types ---\n",
      "int64      36\n",
      "float64    14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Feature statistics ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtime</th>\n",
       "      <th>director_popularity</th>\n",
       "      <th>actor1_popularity</th>\n",
       "      <th>actor2_popularity</th>\n",
       "      <th>actor3_popularity</th>\n",
       "      <th>actor4_popularity</th>\n",
       "      <th>actor5_popularity</th>\n",
       "      <th>cast_pop_mean</th>\n",
       "      <th>cast_pop_max</th>\n",
       "      <th>release_month</th>\n",
       "      <th>...</th>\n",
       "      <th>lang_fr</th>\n",
       "      <th>lang_es</th>\n",
       "      <th>lang_ja</th>\n",
       "      <th>lang_de</th>\n",
       "      <th>lang_other</th>\n",
       "      <th>is_english</th>\n",
       "      <th>has_budget</th>\n",
       "      <th>log_budget</th>\n",
       "      <th>has_overview</th>\n",
       "      <th>overview_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "      <td>9290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.390635</td>\n",
       "      <td>1.209358</td>\n",
       "      <td>2.674343</td>\n",
       "      <td>2.167565</td>\n",
       "      <td>1.829108</td>\n",
       "      <td>1.603090</td>\n",
       "      <td>1.417261</td>\n",
       "      <td>2.023336</td>\n",
       "      <td>4.085244</td>\n",
       "      <td>6.752530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051776</td>\n",
       "      <td>0.046286</td>\n",
       "      <td>0.039182</td>\n",
       "      <td>0.031324</td>\n",
       "      <td>0.212702</td>\n",
       "      <td>0.618730</td>\n",
       "      <td>0.297417</td>\n",
       "      <td>4.709160</td>\n",
       "      <td>0.978364</td>\n",
       "      <td>259.595048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44.067500</td>\n",
       "      <td>1.361564</td>\n",
       "      <td>3.484476</td>\n",
       "      <td>3.548816</td>\n",
       "      <td>2.400900</td>\n",
       "      <td>2.389784</td>\n",
       "      <td>1.819295</td>\n",
       "      <td>1.876921</td>\n",
       "      <td>4.903623</td>\n",
       "      <td>3.463668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221587</td>\n",
       "      <td>0.210116</td>\n",
       "      <td>0.194038</td>\n",
       "      <td>0.174201</td>\n",
       "      <td>0.409241</td>\n",
       "      <td>0.485725</td>\n",
       "      <td>0.457146</td>\n",
       "      <td>7.423386</td>\n",
       "      <td>0.145500</td>\n",
       "      <td>164.951892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.519700</td>\n",
       "      <td>0.400125</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>0.159850</td>\n",
       "      <td>0.836880</td>\n",
       "      <td>1.985875</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.656450</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>1.383700</td>\n",
       "      <td>1.119000</td>\n",
       "      <td>0.907050</td>\n",
       "      <td>0.732900</td>\n",
       "      <td>1.553430</td>\n",
       "      <td>3.254900</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.745450</td>\n",
       "      <td>3.612125</td>\n",
       "      <td>3.078675</td>\n",
       "      <td>2.736150</td>\n",
       "      <td>2.486150</td>\n",
       "      <td>2.214825</td>\n",
       "      <td>2.775495</td>\n",
       "      <td>4.993100</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.815512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>339.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>950.000000</td>\n",
       "      <td>20.877800</td>\n",
       "      <td>88.154000</td>\n",
       "      <td>224.150000</td>\n",
       "      <td>85.498000</td>\n",
       "      <td>145.219000</td>\n",
       "      <td>24.694000</td>\n",
       "      <td>56.784000</td>\n",
       "      <td>224.150000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.009712</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           runtime  director_popularity  actor1_popularity  actor2_popularity  \\\n",
       "count  9290.000000          9290.000000        9290.000000        9290.000000   \n",
       "mean     81.390635             1.209358           2.674343           2.167565   \n",
       "std      44.067500             1.361564           3.484476           3.548816   \n",
       "min       0.000000             0.000000           0.000000           0.000000   \n",
       "25%      67.000000             0.248600           0.519700           0.400125   \n",
       "50%      92.000000             0.656450           1.777000           1.383700   \n",
       "75%     107.000000             1.745450           3.612125           3.078675   \n",
       "max     950.000000            20.877800          88.154000         224.150000   \n",
       "\n",
       "       actor3_popularity  actor4_popularity  actor5_popularity  cast_pop_mean  \\\n",
       "count        9290.000000        9290.000000        9290.000000    9290.000000   \n",
       "mean            1.829108           1.603090           1.417261       2.023336   \n",
       "std             2.400900           2.389784           1.819295       1.876921   \n",
       "min             0.000000           0.000000           0.000000       0.000000   \n",
       "25%             0.311500           0.232275           0.159850       0.836880   \n",
       "50%             1.119000           0.907050           0.732900       1.553430   \n",
       "75%             2.736150           2.486150           2.214825       2.775495   \n",
       "max            85.498000         145.219000          24.694000      56.784000   \n",
       "\n",
       "       cast_pop_max  release_month  ...      lang_fr      lang_es  \\\n",
       "count   9290.000000    9290.000000  ...  9290.000000  9290.000000   \n",
       "mean       4.085244       6.752530  ...     0.051776     0.046286   \n",
       "std        4.903623       3.463668  ...     0.221587     0.210116   \n",
       "min        0.000000       1.000000  ...     0.000000     0.000000   \n",
       "25%        1.985875       4.000000  ...     0.000000     0.000000   \n",
       "50%        3.254900       7.000000  ...     0.000000     0.000000   \n",
       "75%        4.993100      10.000000  ...     0.000000     0.000000   \n",
       "max      224.150000      12.000000  ...     1.000000     1.000000   \n",
       "\n",
       "           lang_ja      lang_de   lang_other   is_english   has_budget  \\\n",
       "count  9290.000000  9290.000000  9290.000000  9290.000000  9290.000000   \n",
       "mean      0.039182     0.031324     0.212702     0.618730     0.297417   \n",
       "std       0.194038     0.174201     0.409241     0.485725     0.457146   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        log_budget  has_overview  overview_length  \n",
       "count  9290.000000   9290.000000      9290.000000  \n",
       "mean      4.709160      0.978364       259.595048  \n",
       "std       7.423386      0.145500       164.951892  \n",
       "min       0.000000      0.000000         0.000000  \n",
       "25%       0.000000      1.000000       146.000000  \n",
       "50%       0.000000      1.000000       220.000000  \n",
       "75%      13.815512      1.000000       339.000000  \n",
       "max      20.009712      1.000000       999.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 14. Define Pre-Release Feature Columns\n",
    "\n",
    "Define the list of columns that constitute valid pre-release features. These will be used in all feature matrices for modeling. Post-release variables (popularity, vote_average, vote_count) and raw targets (revenue, budget) are explicitly excluded from feature matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99019e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Define pre-release feature columns\n",
    "# ============================================================\n",
    "\n",
    "# Columns that must NOT be used as features when predicting revenue\n",
    "post_release_exclude = [\"popularity\", \"vote_average\", \"vote_count\"]\n",
    "target_exclude = [\"revenue\", \"budget\", \"revenue_tier\", \"revenue_missing_flag\"]\n",
    "# budget_missing_flag is a valid feature (it's known pre-release)\n",
    "# but raw budget is replaced by log_budget + has_budget\n",
    "\n",
    "# All pre-release feature columns\n",
    "all_master_cols = list(data_features_master.columns)\n",
    "non_feature_cols = post_release_exclude + [\"revenue\", \"budget\", \"revenue_tier\"]\n",
    "\n",
    "pre_release_features = [c for c in all_master_cols if c not in non_feature_cols]\n",
    "\n",
    "print(f\"Pre-release feature columns ({len(pre_release_features)}):\")\n",
    "print(pre_release_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288daa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/data_cleaned_engineered.csv\n"
     ]
    }
   ],
   "source": [
    "## 15. Dataset Builder Functions\n",
    "\n",
    "Three functions to construct task-specific datasets from the master:\n",
    "\n",
    "1. **`build_supervised_dataset(target)`** — For supervised models (revenue or popularity)\n",
    "2. **`build_ssl_dataset()`** — For semi-supervised revenue classification (all rows, y_ssl = tier or -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Dataset builder: Supervised\n",
    "# ============================================================\n",
    "def build_supervised_dataset(master_df, target=\"revenue\"):\n",
    "    \"\"\"\n",
    "    Build a supervised dataset from the master.\n",
    "    \n",
    "    Parameters:\n",
    "        master_df: the master feature dataframe\n",
    "        target: \"revenue\" or \"popularity\"\n",
    "    \n",
    "    Returns:\n",
    "        X (features DataFrame), y (target Series)\n",
    "    \"\"\"\n",
    "    if target == \"revenue\":\n",
    "        # Only rows where revenue is not NaN\n",
    "        df_sub = master_df[master_df[\"revenue\"].notna()].copy()\n",
    "        y = df_sub[\"revenue\"].copy()\n",
    "        \n",
    "        # Exclude post-release + raw targets from features\n",
    "        exclude = [\"popularity\", \"vote_average\", \"vote_count\",\n",
    "                    \"revenue\", \"budget\", \"revenue_tier\"]\n",
    "        X = df_sub.drop(columns=[c for c in exclude if c in df_sub.columns])\n",
    "        \n",
    "    elif target == \"popularity\":\n",
    "        # Only rows where popularity is not NaN\n",
    "        df_sub = master_df[master_df[\"popularity\"].notna()].copy()\n",
    "        y = df_sub[\"popularity\"].copy()\n",
    "        \n",
    "        # Exclude revenue + other post-release from features\n",
    "        exclude = [\"popularity\", \"vote_average\", \"vote_count\",\n",
    "                    \"revenue\", \"budget\", \"revenue_tier\"]\n",
    "        X = df_sub.drop(columns=[c for c in exclude if c in df_sub.columns])\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown target: {target}. Use 'revenue' or 'popularity'.\")\n",
    "    \n",
    "    print(f\"Supervised dataset for '{target}':\")\n",
    "    print(f\"  X shape: {X.shape}\")\n",
    "    print(f\"  y shape: {y.shape}\")\n",
    "    print(f\"  Features: {list(X.columns)}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataset builder: Semi-Supervised (SSL) for Revenue\n",
    "# ============================================================\n",
    "def build_ssl_dataset(master_df):\n",
    "    \"\"\"\n",
    "    Build a semi-supervised dataset for revenue tier classification.\n",
    "    \n",
    "    - All rows included\n",
    "    - y_ssl = revenue_tier label (encoded as int) if revenue is not NaN\n",
    "    - y_ssl = -1 if revenue is NaN (unlabeled)\n",
    "    - No post-release features in X\n",
    "    \n",
    "    Returns:\n",
    "        X (features DataFrame), y_ssl (Series with int labels or -1)\n",
    "    \"\"\"\n",
    "    df_ssl = master_df.copy()\n",
    "    \n",
    "    # Encode revenue_tier as integers for sklearn semi-supervised classifiers\n",
    "    tier_map = {\"Low\": 0, \"Medium\": 1, \"High\": 2, \"Blockbuster\": 3}\n",
    "    \n",
    "    # Create y_ssl: mapped tier or -1 for unlabeled\n",
    "    df_ssl[\"y_ssl\"] = df_ssl[\"revenue_tier\"].map(tier_map).fillna(-1).astype(int)\n",
    "    \n",
    "    y_ssl = df_ssl[\"y_ssl\"].copy()\n",
    "    \n",
    "    # Exclude post-release + raw targets from features\n",
    "    exclude = [\"popularity\", \"vote_average\", \"vote_count\",\n",
    "                \"revenue\", \"budget\", \"revenue_tier\", \"y_ssl\"]\n",
    "    X = df_ssl.drop(columns=[c for c in exclude if c in df_ssl.columns])\n",
    "    \n",
    "    print(f\"SSL dataset for revenue tier:\")\n",
    "    print(f\"  X shape: {X.shape}\")\n",
    "    print(f\"  y_ssl shape: {y_ssl.shape}\")\n",
    "    print(f\"  Labeled:   {(y_ssl != -1).sum()}\")\n",
    "    print(f\"  Unlabeled: {(y_ssl == -1).sum()}\")\n",
    "    print(f\"  y_ssl distribution:\\n{y_ssl.value_counts().sort_index().to_dict()}\")\n",
    "    print(f\"  Features: {list(X.columns)}\")\n",
    "    return X, y_ssl\n",
    "\n",
    "\n",
    "print(\"Dataset builder functions defined: build_supervised_dataset(), build_ssl_dataset()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b84ab",
   "metadata": {},
   "source": [
    "## 16. Scaling Preparation for Graph-Based SSL\n",
    "\n",
    "LabelPropagation and LabelSpreading use distance-based kernels (RBF) and are sensitive to feature scales. A `StandardScaler` pipeline is prepared here. **Scaling must be applied after train/test split** to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Scaling pipeline for graph-based SSL (LabelPropagation / LabelSpreading)\n",
    "# ============================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "\n",
    "def create_ssl_scaling_pipeline(model_class=LabelSpreading, **model_kwargs):\n",
    "    \"\"\"\n",
    "    Create a Pipeline with StandardScaler + SSL classifier.\n",
    "    \n",
    "    IMPORTANT: Apply this AFTER train/test split to prevent leakage.\n",
    "    The scaler fits only on training data.\n",
    "    \n",
    "    Usage:\n",
    "        pipe = create_ssl_scaling_pipeline(LabelSpreading, kernel='rbf', gamma=20)\n",
    "        pipe.fit(X_train, y_train_ssl)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ssl_model\", model_class(**model_kwargs))\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "print(\"Scaling pipeline function defined: create_ssl_scaling_pipeline()\")\n",
    "print(\"Example: pipe = create_ssl_scaling_pipeline(LabelSpreading, kernel='rbf', gamma=20)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432fa06",
   "metadata": {},
   "source": [
    "## 17. Dataset Validation Checks\n",
    "\n",
    "Before exporting, validate:\n",
    "- Labeled vs unlabeled observation counts\n",
    "- Revenue tier class distribution\n",
    "- Missing values per feature\n",
    "- Confirm no post-release columns in SSL feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Validation checks\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Labeled vs Unlabeled revenue observations\n",
    "n_labeled = data_features_master[\"revenue\"].notna().sum()\n",
    "n_unlabeled = data_features_master[\"revenue\"].isna().sum()\n",
    "print(f\"\\n1. Revenue observations:\")\n",
    "print(f\"   Labeled (revenue known):   {n_labeled}\")\n",
    "print(f\"   Unlabeled (revenue NaN):   {n_unlabeled}\")\n",
    "print(f\"   Total:                     {n_labeled + n_unlabeled}\")\n",
    "\n",
    "# 2. Revenue tier distribution\n",
    "print(f\"\\n2. Revenue tier distribution:\")\n",
    "print(data_features_master[\"revenue_tier\"].value_counts())\n",
    "print(f\"   NaN (unlabeled): {data_features_master['revenue_tier'].isna().sum()}\")\n",
    "\n",
    "# 3. Missing values per feature\n",
    "print(f\"\\n3. Missing values per column (top 15):\")\n",
    "missing = data_features_master.isnull().sum().sort_values(ascending=False)\n",
    "missing_pct = (missing / len(data_features_master) * 100).round(2)\n",
    "missing_report = pd.DataFrame({\"count\": missing, \"pct\": missing_pct})\n",
    "print(missing_report[missing_report[\"count\"] > 0].head(15))\n",
    "\n",
    "# 4. Build SSL dataset and verify no post-release leakage\n",
    "print(f\"\\n4. SSL feature matrix leakage check:\")\n",
    "X_ssl_check, y_ssl_check = build_ssl_dataset(data_features_master)\n",
    "forbidden_in_ssl = [\"popularity\", \"vote_average\", \"vote_count\", \"revenue\", \"revenue_tier\"]\n",
    "leakage_found = [c for c in forbidden_in_ssl if c in X_ssl_check.columns]\n",
    "if leakage_found:\n",
    "    print(f\"   WARNING: Post-release leakage detected: {leakage_found}\")\n",
    "else:\n",
    "    print(f\"   PASSED - No post-release columns in SSL feature matrix\")\n",
    "\n",
    "# 5. Supervised dataset check\n",
    "print(f\"\\n5. Supervised revenue dataset check:\")\n",
    "X_rev_check, y_rev_check = build_supervised_dataset(data_features_master, target=\"revenue\")\n",
    "leakage_rev = [c for c in forbidden_in_ssl if c in X_rev_check.columns]\n",
    "if leakage_rev:\n",
    "    print(f\"   WARNING: Leakage detected: {leakage_rev}\")\n",
    "else:\n",
    "    print(f\"   PASSED - No post-release columns in supervised revenue features\")\n",
    "\n",
    "print(f\"\\n6. Supervised popularity dataset check:\")\n",
    "X_pop_check, y_pop_check = build_supervised_dataset(data_features_master, target=\"popularity\")\n",
    "leakage_pop = [c for c in [\"popularity\", \"revenue\", \"revenue_tier\"] if c in X_pop_check.columns]\n",
    "if leakage_pop:\n",
    "    print(f\"   WARNING: Leakage detected: {leakage_pop}\")\n",
    "else:\n",
    "    print(f\"   PASSED - No target leakage in supervised popularity features\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"Revenue tier thresholds (for reproducibility):\")\n",
    "for k, v in revenue_tier_thresholds.items():\n",
    "    print(f\"  {k}: ${v:,.0f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43928fd",
   "metadata": {},
   "source": [
    "## 18. Export Clean Outputs\n",
    "\n",
    "Export four datasets:\n",
    "1. **data_features_master.csv** — neutral master (all rows, all features + raw targets)\n",
    "2. **data_supervised_revenue.csv** — labeled rows, pre-release features + revenue target\n",
    "3. **data_supervised_popularity.csv** — labeled rows, pre-release features + popularity target\n",
    "4. **data_ssl_revenue.csv** — all rows, pre-release features + y_ssl column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b32075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Export all datasets\n",
    "# ============================================================\n",
    "import os\n",
    "\n",
    "output_dir = \"../data\"\n",
    "\n",
    "# 1. Master dataset\n",
    "master_path = os.path.join(output_dir, \"data_features_master.csv\")\n",
    "data_features_master.to_csv(master_path, index=False)\n",
    "print(f\"[1/4] Saved: {master_path}  shape={data_features_master.shape}\")\n",
    "\n",
    "# 2. Supervised revenue dataset\n",
    "X_rev, y_rev = build_supervised_dataset(data_features_master, target=\"revenue\")\n",
    "sup_rev = X_rev.copy()\n",
    "sup_rev[\"revenue\"] = y_rev.values\n",
    "sup_rev_path = os.path.join(output_dir, \"data_supervised_revenue.csv\")\n",
    "sup_rev.to_csv(sup_rev_path, index=False)\n",
    "print(f\"[2/4] Saved: {sup_rev_path}  shape={sup_rev.shape}\")\n",
    "\n",
    "# 3. Supervised popularity dataset\n",
    "X_pop, y_pop = build_supervised_dataset(data_features_master, target=\"popularity\")\n",
    "sup_pop = X_pop.copy()\n",
    "sup_pop[\"popularity\"] = y_pop.values\n",
    "sup_pop_path = os.path.join(output_dir, \"data_supervised_popularity.csv\")\n",
    "sup_pop.to_csv(sup_pop_path, index=False)\n",
    "print(f\"[3/4] Saved: {sup_pop_path}  shape={sup_pop.shape}\")\n",
    "\n",
    "# 4. SSL revenue dataset\n",
    "X_ssl, y_ssl = build_ssl_dataset(data_features_master)\n",
    "ssl_rev = X_ssl.copy()\n",
    "ssl_rev[\"y_ssl\"] = y_ssl.values\n",
    "ssl_rev_path = os.path.join(output_dir, \"data_ssl_revenue.csv\")\n",
    "ssl_rev.to_csv(ssl_rev_path, index=False)\n",
    "print(f\"[4/4] Saved: {ssl_rev_path}  shape={ssl_rev.shape}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL EXPORTS COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a05ca",
   "metadata": {},
   "source": [
    "## Final System Structure\n",
    "\n",
    "| Component | Description |\n",
    "|---|---|\n",
    "| **data_features_master.csv** | Neutral master dataset — all rows, all pre-release features, raw targets, missing flags |\n",
    "| **data_supervised_revenue.csv** | Labeled rows only, pre-release features + revenue |\n",
    "| **data_supervised_popularity.csv** | Labeled rows only, pre-release features + popularity |\n",
    "| **data_ssl_revenue.csv** | All rows, pre-release features + y_ssl (tier label or -1) |\n",
    "| **build_supervised_dataset()** | Function to construct supervised X, y for revenue or popularity |\n",
    "| **build_ssl_dataset()** | Function to construct SSL X, y_ssl with -1 for unlabeled |\n",
    "| **create_ssl_scaling_pipeline()** | StandardScaler + SSL model pipeline (apply after split) |\n",
    "\n",
    "**Guarantees:**\n",
    "- No target leakage (post-release variables excluded from feature matrices)\n",
    "- Revenue tiers computed only from labeled observations\n",
    "- Zero values in budget/revenue corrected to NaN with flags\n",
    "- All pre-release variables preserved\n",
    "- Missing revenue rows retained as unlabeled for SSL\n",
    "- Reproducible quantile thresholds documented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
