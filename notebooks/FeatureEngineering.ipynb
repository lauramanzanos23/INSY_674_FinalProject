{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1a0d49",
   "metadata": {},
   "source": [
    "\n",
    "# Feature Engineering & Data Cleaning (TMDB 2010-2025)\n",
    "\n",
    "Goal: clean `movies_2010_2025.csv` and create model-ready features for **semi-supervised** learning to predict movie popularity or success. This notebook focuses on **data quality + feature engineering** only (no modeling).\n",
    "\n",
    "Outputs:\n",
    "- `data/data_cleaned_engineered.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f546c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d356815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "path = \"../data/movies_2010_2025.csv\"\n",
    "df = pd.read_csv(path)\n",
    "print(df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic cleanup\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# Drop duplicate movies by movie_id (keep first)\n",
    "if \"movie_id\" in df.columns:\n",
    "    df = df.drop_duplicates(subset=[\"movie_id\"])\n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f762551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parse dates and create time features\n",
    "\n",
    "df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "\n",
    "df[\"release_year\"] = df[\"release_date\"].dt.year\n",
    "\n",
    "df[\"release_month\"] = df[\"release_date\"].dt.month\n",
    "\n",
    "df[\"release_quarter\"] = df[\"release_date\"].dt.quarter\n",
    "\n",
    "df[\"release_dayofweek\"] = df[\"release_date\"].dt.dayofweek\n",
    "\n",
    "df[\"release_weekofyear\"] = df[\"release_date\"].dt.isocalendar().week.astype(\"Int64\")\n",
    "\n",
    "df[\"is_weekend_release\"] = df[\"release_dayofweek\"].isin([4, 5, 6]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize numeric columns and handle invalid/zero values\n",
    "\n",
    "numeric_cols = [\n",
    "    \"runtime\", \"popularity\", \"vote_average\", \"vote_count\",\n",
    "    \"budget\", \"revenue\",\n",
    "    \"director_popularity\",\n",
    "    \"actor1_popularity\", \"actor2_popularity\", \"actor3_popularity\", \"actor4_popularity\", \"actor5_popularity\",\n",
    "    \"cast_pop_mean\", \"cast_pop_max\",\n",
    "]\n",
    "\n",
    "for c in numeric_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Treat zeros as missing for runtime, budget, revenue (common TMDB pattern)\n",
    "for c in [\"runtime\", \"budget\", \"revenue\"]:\n",
    "    if c in df.columns:\n",
    "        df.loc[df[c] == 0, c] = np.nan\n",
    "\n",
    "# Missing flags\n",
    "for c in [\"runtime\", \"budget\", \"revenue\", \"director_popularity\"]:\n",
    "    if c in df.columns:\n",
    "        df[f\"{c}_missing\"] = df[c].isna().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47db726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Text-based features\n",
    "\n",
    "def safe_str(x):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return str(x)\n",
    "\n",
    "# Overview length features\n",
    "if \"overview\" in df.columns:\n",
    "    df[\"overview_len\"] = df[\"overview\"].map(lambda x: len(safe_str(x)))\n",
    "    df[\"overview_word_count\"] = df[\"overview\"].map(lambda x: len(safe_str(x).split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c946669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parse list-like columns\n",
    "\n",
    "def parse_list_column(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "list_cols = [\"genres\", \"keywords\"]\n",
    "for c in list_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].map(parse_list_column)\n",
    "\n",
    "# Count features\n",
    "if \"genres\" in df.columns:\n",
    "    df[\"genres_count\"] = df[\"genres\"].map(len)\n",
    "if \"keywords\" in df.columns:\n",
    "    df[\"keywords_count\"] = df[\"keywords\"].map(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create top-N genre dummies (kept moderate for modeling)\n",
    "if \"genres\" in df.columns:\n",
    "    all_genres = pd.Series([g for sub in df[\"genres\"] for g in sub])\n",
    "    top_genres = all_genres.value_counts().head(15).index.tolist()\n",
    "\n",
    "    for g in top_genres:\n",
    "        df[f\"genre_{g.lower().replace(' ', '_').replace('-', '_')}\"] = df[\"genres\"].map(lambda xs: int(g in xs))\n",
    "\n",
    "# Primary genre feature (first listed)\n",
    "if \"genres\" in df.columns:\n",
    "    df[\"primary_genre\"] = df[\"genres\"].map(lambda xs: xs[0] if len(xs) > 0 else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create top-N keyword dummies (use a small set to control dimensionality)\n",
    "if \"keywords\" in df.columns:\n",
    "    all_keywords = pd.Series([k for sub in df[\"keywords\"] for k in sub])\n",
    "    top_keywords = all_keywords.value_counts().head(25).index.tolist()\n",
    "\n",
    "    for k in top_keywords:\n",
    "        safe = k.lower().replace(' ', '_').replace('-', '_').replace(',', '').replace('(', '').replace(')', '')\n",
    "        df[f\"kw_{safe}\"] = df[\"keywords\"].map(lambda xs: int(k in xs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Talent/cast features\n",
    "actor_pop_cols = [\"actor1_popularity\", \"actor2_popularity\", \"actor3_popularity\", \"actor4_popularity\", \"actor5_popularity\"]\n",
    "existing_actor_pop_cols = [c for c in actor_pop_cols if c in df.columns]\n",
    "\n",
    "if existing_actor_pop_cols:\n",
    "    df[\"actor_pop_mean\"] = df[existing_actor_pop_cols].mean(axis=1, skipna=True)\n",
    "    df[\"actor_pop_max\"] = df[existing_actor_pop_cols].max(axis=1, skipna=True)\n",
    "    df[\"actor_pop_min\"] = df[existing_actor_pop_cols].min(axis=1, skipna=True)\n",
    "    df[\"actor_pop_std\"] = df[existing_actor_pop_cols].std(axis=1, skipna=True)\n",
    "\n",
    "# Count cast members with names (proxy for cast size)\n",
    "actor_name_cols = [\"actor1_name\", \"actor2_name\", \"actor3_name\", \"actor4_name\", \"actor5_name\"]\n",
    "existing_actor_name_cols = [c for c in actor_name_cols if c in df.columns]\n",
    "if existing_actor_name_cols:\n",
    "    df[\"cast_size\"] = df[existing_actor_name_cols].notna().sum(axis=1)\n",
    "\n",
    "# Gender counts (TMDB: 1=female, 2=male, 0=not set, 3=non-binary)\n",
    "# We compute counts across director + top 5 cast\n",
    "\n",
    "gender_cols = [\"director_gender\", \"actor1_gender\", \"actor2_gender\", \"actor3_gender\", \"actor4_gender\", \"actor5_gender\"]\n",
    "existing_gender_cols = [c for c in gender_cols if c in df.columns]\n",
    "\n",
    "if existing_gender_cols:\n",
    "    gdf = df[existing_gender_cols]\n",
    "    df[\"gender_female_count\"] = (gdf == 1).sum(axis=1)\n",
    "    df[\"gender_male_count\"] = (gdf == 2).sum(axis=1)\n",
    "    df[\"gender_nonbinary_count\"] = (gdf == 3).sum(axis=1)\n",
    "    df[\"gender_unknown_count\"] = (gdf == 0).sum(axis=1)\n",
    "    df[\"has_female_director\"] = (df[\"director_gender\"] == 1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Financial features (use with care depending on target)\n",
    "if \"budget\" in df.columns:\n",
    "    df[\"log_budget\"] = np.log1p(df[\"budget\"])\n",
    "if \"revenue\" in df.columns:\n",
    "    df[\"log_revenue\"] = np.log1p(df[\"revenue\"])\n",
    "\n",
    "if \"budget\" in df.columns and \"revenue\" in df.columns:\n",
    "    df[\"roi\"] = df[\"revenue\"] / df[\"budget\"]\n",
    "    df.loc[(df[\"budget\"].isna()) | (df[\"revenue\"].isna()) | (df[\"budget\"] == 0), \"roi\"] = np.nan\n",
    "\n",
    "    # Success label candidates (binary) for downstream modeling\n",
    "    df[\"has_financials\"] = (~df[\"budget\"].isna()) & (~df[\"revenue\"].isna())\n",
    "    df[\"success_revenue\"] = ((df[\"has_financials\"]) & (df[\"revenue\"] > df[\"budget\"]))\n",
    "    df[\"success_roi_1_5\"] = ((df[\"has_financials\"]) & (df[\"roi\"] >= 1.5))\n",
    "    df[\"success_revenue\"] = df[\"success_revenue\"].astype(int)\n",
    "    df[\"success_roi_1_5\"] = df[\"success_roi_1_5\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8362da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Impute missing numeric values for modeling (keep flags from earlier)\n",
    "\n",
    "# Exclude known target columns from imputation if desired later\n",
    "numeric_cols_for_impute = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# We avoid imputing target-ish columns here (popularity, vote_average, vote_count, revenue)\n",
    "avoid_impute = {\"popularity\", \"vote_average\", \"vote_count\", \"revenue\"}\n",
    "\n",
    "for c in numeric_cols_for_impute:\n",
    "    if c in avoid_impute:\n",
    "        continue\n",
    "    if df[c].isna().any():\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "print(df.isna().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1496d1",
   "metadata": {},
   "source": [
    "\n",
    "### Notes for downstream modeling\n",
    "- **Targets** (choose one depending on task): `popularity`, `success_revenue`, or `success_roi_1_5`.\n",
    "- **Potential leakage**: if predicting success, exclude `revenue`, `log_revenue`, and `roi` from features.\n",
    "- **Semi-supervised setup**: use `has_financials` to mask labels for success targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153764c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export\n",
    "out_path = \"../data/data_cleaned_engineered.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
