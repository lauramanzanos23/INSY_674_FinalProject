{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bbda13",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning — Revenue Tier Classification\n",
    "\n",
    "**Goal:** Compare a supervised baseline against three semi-supervised methodologies and select the best-performing model for revenue tier prediction, evaluated on macro F1 on a held-out labeled test set.\n",
    "\n",
    "**Dataset:** `data_ssl_revenue.csv` produced by the Feature Engineering pipeline.\n",
    "\n",
    "**Target:** `y_ssl`\n",
    "- 0 = Low, 1 = Medium, 2 = High, 3 = Blockbuster (labeled)\n",
    "- -1 = unlabeled\n",
    "\n",
    "**Models:**\n",
    "1. GradientBoosting (supervised baseline)\n",
    "2. RandomForest (supervised baseline)\n",
    "3. SelfTraining (semi-supervised)\n",
    "4. LabelSpreading (semi-supervised, graph-based)\n",
    "5. LabelPropagation (semi-supervised, graph-based)\n",
    "\n",
    "**Theoretical guarantees:**\n",
    "- Train/test split on labeled data only\n",
    "- Test set never participates in pseudo-labeling\n",
    "- Unlabeled data used only during SSL fitting\n",
    "- No post-release variables as features\n",
    "- Scaler fitted only on labeled train\n",
    "- PCA (if used) fitted only on training data\n",
    "- All models evaluated on the same labeled test set\n",
    "- Primary metric: macro F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56948d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.semi_supervised import (\n",
    "    SelfTrainingClassifier,\n",
    "    LabelSpreading,\n",
    "    LabelPropagation,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"All imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb8adc",
   "metadata": {},
   "source": [
    "## 0. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Load the SSL revenue dataset\n",
    "# ============================================================\n",
    "DATA_DIR = \"../data\"\n",
    "ARTIFACTS_DIR = \"../data\"  # save artifacts alongside datasets\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, \"data_ssl_revenue.csv\"))\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\ny_ssl value counts:\\n{df['y_ssl'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09842593",
   "metadata": {},
   "source": [
    "---\n",
    "## Validation 1 — Leakage Prevention\n",
    "\n",
    "Remove any column whose name contains post-release or target keywords (`vote`, `review`, `rating`, `popularity`, `revenue`, `budget`). Keep `y_ssl` only as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Validation 1 — Leakage prevention\n",
    "# ============================================================\n",
    "leakage_keywords = [\"vote\", \"review\", \"rating\", \"popularity\", \"revenue\", \"budget\"]\n",
    "\n",
    "# All columns except y_ssl are candidate features\n",
    "candidate_features = [c for c in df.columns if c != \"y_ssl\"]\n",
    "\n",
    "# Remove any column whose name contains a leakage keyword\n",
    "leaked_cols = [c for c in candidate_features\n",
    "               if any(kw in c.lower() for kw in leakage_keywords)]\n",
    "\n",
    "feature_cols = [c for c in candidate_features if c not in leaked_cols]\n",
    "\n",
    "print(f\"Candidate features before filter: {len(candidate_features)}\")\n",
    "print(f\"Leaked columns removed ({len(leaked_cols)}): {leaked_cols}\")\n",
    "print(f\"\\nFinal feature count: {len(feature_cols)}\")\n",
    "print(f\"First 20 features: {feature_cols[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406cc5ea",
   "metadata": {},
   "source": [
    "## Validation 2 — Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ea463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Validation 2 — Class distribution (labeled data)\n",
    "# ============================================================\n",
    "labeled_mask = df[\"y_ssl\"] != -1\n",
    "df_labeled = df[labeled_mask].copy()\n",
    "\n",
    "class_counts = df_labeled[\"y_ssl\"].value_counts().sort_index()\n",
    "print(f\"Class distribution (labeled rows):\")\n",
    "tier_names = {0: \"Low\", 1: \"Medium\", 2: \"High\", 3: \"Blockbuster\"}\n",
    "for cls, cnt in class_counts.items():\n",
    "    print(f\"  {cls} ({tier_names.get(cls, '?')}): {cnt}\")\n",
    "\n",
    "n_classes = df_labeled[\"y_ssl\"].nunique()\n",
    "print(f\"\\nNumber of classes: {n_classes}\")\n",
    "assert n_classes == 4, f\"Expected 4 classes, got {n_classes}\"\n",
    "print(f\"Total labeled rows: {len(df_labeled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e50b46",
   "metadata": {},
   "source": [
    "## Validation 3 — Unlabeled Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8960d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Validation 3 — Unlabeled proportion\n",
    "# ============================================================\n",
    "unlabeled_mask = df[\"y_ssl\"] == -1\n",
    "n_unlabeled = unlabeled_mask.sum()\n",
    "pct_unlabeled = n_unlabeled / len(df) * 100\n",
    "\n",
    "print(f\"Unlabeled rows:  {n_unlabeled}\")\n",
    "print(f\"Percentage:      {pct_unlabeled:.2f}%\")\n",
    "print(f\"Labeled rows:    {(~unlabeled_mask).sum()}\")\n",
    "print(f\"Total rows:      {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c603934",
   "metadata": {},
   "source": [
    "## Validation 4 — Feature Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a36e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Validation 4 — Feature dimensionality\n",
    "# ============================================================\n",
    "n_features = len(feature_cols)\n",
    "USE_PCA = n_features > 100\n",
    "\n",
    "print(f\"Total feature columns: {n_features}\")\n",
    "if USE_PCA:\n",
    "    print(\">> Feature count > 100 — will apply PCA (95% variance) for graph-based SSL methods.\")\n",
    "else:\n",
    "    print(\">> Feature count <= 100 — no PCA needed for graph-based methods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a886f",
   "metadata": {},
   "source": [
    "## Validation 5 — Missing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65142b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Validation 5 — Missing features\n",
    "# ============================================================\n",
    "X_all = df[feature_cols].copy()\n",
    "y_all = df[\"y_ssl\"].copy()\n",
    "\n",
    "missing_before = X_all.isnull().sum()\n",
    "total_missing_before = missing_before.sum()\n",
    "print(f\"Total missing values BEFORE imputation: {total_missing_before}\")\n",
    "\n",
    "if total_missing_before > 0:\n",
    "    print(f\"\\nMissing per column (non-zero):\")\n",
    "    print(missing_before[missing_before > 0])\n",
    "    \n",
    "    # Apply median imputation for numeric columns\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_all_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(X_all),\n",
    "        columns=feature_cols,\n",
    "        index=X_all.index\n",
    "    )\n",
    "    total_missing_after = X_all_imputed.isnull().sum().sum()\n",
    "    print(f\"\\nTotal missing values AFTER imputation: {total_missing_after}\")\n",
    "    X_all = X_all_imputed\n",
    "else:\n",
    "    print(\"No missing values — no imputation needed.\")\n",
    "\n",
    "print(f\"\\nFinal feature matrix shape: {X_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fe63c",
   "metadata": {},
   "source": [
    "---\n",
    "# Experiment\n",
    "\n",
    "## Step 1 — Split Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 1 — Split labeled data only\n",
    "# ============================================================\n",
    "\n",
    "# Separate labeled and unlabeled feature matrices\n",
    "X_labeled = X_all[labeled_mask].copy()\n",
    "y_labeled = y_all[labeled_mask].copy()\n",
    "X_unlabeled = X_all[unlabeled_mask].copy()\n",
    "\n",
    "print(f\"Labeled:   X={X_labeled.shape}  y={y_labeled.shape}\")\n",
    "print(f\"Unlabeled: X={X_unlabeled.shape}\")\n",
    "\n",
    "# Stratified train/test split on labeled data\n",
    "X_train_labeled, X_test, y_train, y_test = train_test_split(\n",
    "    X_labeled, y_labeled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_labeled\n",
    ")\n",
    "\n",
    "print(f\"\\nAfter split:\")\n",
    "print(f\"  X_train_labeled: {X_train_labeled.shape}\")\n",
    "print(f\"  X_test:          {X_test.shape}\")\n",
    "print(f\"  y_train:         {y_train.shape}  distribution: {dict(y_train.value_counts().sort_index())}\")\n",
    "print(f\"  y_test:          {y_test.shape}  distribution: {dict(y_test.value_counts().sort_index())}\")\n",
    "print(f\"  X_unlabeled:     {X_unlabeled.shape}\")\n",
    "print(f\"\\n>> Test set ({len(y_test)} rows) will NEVER be used during SSL fitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d5756",
   "metadata": {},
   "source": [
    "## Step 2 — Preprocessing (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 2 — Fit StandardScaler on labeled train ONLY\n",
    "# ============================================================\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_labeled)\n",
    "\n",
    "X_train_s = pd.DataFrame(\n",
    "    scaler.transform(X_train_labeled),\n",
    "    columns=feature_cols, index=X_train_labeled.index\n",
    ")\n",
    "X_test_s = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=feature_cols, index=X_test.index\n",
    ")\n",
    "X_unlabeled_s = pd.DataFrame(\n",
    "    scaler.transform(X_unlabeled),\n",
    "    columns=feature_cols, index=X_unlabeled.index\n",
    ")\n",
    "\n",
    "print(\"StandardScaler fitted on labeled training data only.\")\n",
    "print(f\"  X_train_s:     {X_train_s.shape}\")\n",
    "print(f\"  X_test_s:      {X_test_s.shape}\")\n",
    "print(f\"  X_unlabeled_s: {X_unlabeled_s.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff390a8",
   "metadata": {},
   "source": [
    "## Step 3 — Supervised Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ea742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Helper: evaluate a model and return metrics dict\n",
    "# ============================================================\n",
    "def evaluate_model(model, X_eval, y_eval, model_name, notes=\"\"):\n",
    "    \"\"\"\n",
    "    Predict on X_eval and compute accuracy, macro_f1, confusion matrix.\n",
    "    Returns a dict suitable for the comparison table.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_eval)\n",
    "    acc = accuracy_score(y_eval, y_pred)\n",
    "    f1 = f1_score(y_eval, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_eval, y_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Macro F1:  {f1:.4f}\")\n",
    "    print(f\"\\n  Classification Report:\")\n",
    "    print(classification_report(y_eval, y_pred, target_names=[\"Low\", \"Medium\", \"High\", \"Blockbuster\"]))\n",
    "    print(f\"  Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"macro_f1\": round(f1, 4),\n",
    "        \"notes\": notes,\n",
    "        \"_model\": model,\n",
    "        \"_y_pred\": y_pred,\n",
    "        \"_cm\": cm,\n",
    "    }\n",
    "\n",
    "print(\"Evaluation helper defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 3a — Gradient Boosting (supervised baseline)\n",
    "# ============================================================\n",
    "results = []\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf.fit(X_train_s, y_train)\n",
    "\n",
    "res_gb = evaluate_model(gb_clf, X_test_s, y_test,\n",
    "                        \"GradientBoosting (supervised)\",\n",
    "                        notes=\"Supervised baseline\")\n",
    "results.append(res_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85814d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 3b — Random Forest (supervised baseline)\n",
    "# ============================================================\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train_s, y_train)\n",
    "\n",
    "res_rf = evaluate_model(rf_clf, X_test_s, y_test,\n",
    "                        \"RandomForest (supervised)\",\n",
    "                        notes=\"Supervised baseline\")\n",
    "results.append(res_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ddfefd",
   "metadata": {},
   "source": [
    "## Step 4 — Prepare Semi-Supervised Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 4 — Concatenate labeled train + unlabeled for SSL\n",
    "# ============================================================\n",
    "X_train_ssl = pd.concat([X_train_s, X_unlabeled_s], axis=0).reset_index(drop=True)\n",
    "y_train_ssl = pd.concat([\n",
    "    y_train.reset_index(drop=True),\n",
    "    pd.Series([-1] * len(X_unlabeled_s))\n",
    "], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(f\"SSL training data:\")\n",
    "print(f\"  X_train_ssl: {X_train_ssl.shape}\")\n",
    "print(f\"  y_train_ssl: {y_train_ssl.shape}\")\n",
    "print(f\"  Labeled in SSL train:   {(y_train_ssl != -1).sum()}\")\n",
    "print(f\"  Unlabeled in SSL train: {(y_train_ssl == -1).sum()}\")\n",
    "print(f\"\\n>> Test set ({len(y_test)} rows) is EXCLUDED from SSL training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca186c3f",
   "metadata": {},
   "source": [
    "## Step 5 — Semi-Supervised Models\n",
    "\n",
    "### Model A: Self-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0688dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Model A — Self-Training with RandomForest base estimator\n",
    "# ============================================================\n",
    "st_base = RandomForestClassifier(random_state=42)\n",
    "st_clf = SelfTrainingClassifier(\n",
    "    base_estimator=st_base,\n",
    "    threshold=0.9,\n",
    "    verbose=False\n",
    ")\n",
    "st_clf.fit(X_train_ssl, y_train_ssl)\n",
    "\n",
    "# Count pseudo-labeled samples\n",
    "if hasattr(st_clf, \"labeled_iter_\"):\n",
    "    # labeled_iter_ > 0 means pseudo-labeled in that iteration\n",
    "    n_pseudo = int((st_clf.labeled_iter_ > 0).sum())\n",
    "    st_notes = f\"Pseudo-labeled: {n_pseudo} samples\"\n",
    "else:\n",
    "    n_pseudo = \"N/A\"\n",
    "    st_notes = \"Pseudo-label count not available\"\n",
    "\n",
    "print(f\"Self-Training complete. {st_notes}\")\n",
    "\n",
    "res_st = evaluate_model(st_clf, X_test_s, y_test,\n",
    "                        \"SelfTraining (SSL)\",\n",
    "                        notes=st_notes)\n",
    "results.append(res_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c327c6",
   "metadata": {},
   "source": [
    "### PCA Preparation for Graph-Based Methods\n",
    "\n",
    "LabelSpreading and LabelPropagation use distance-based kernels. If the feature dimensionality is high (>100), we reduce it with PCA (retaining 95% explained variance). PCA is fitted **only on the SSL training data** to prevent leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PCA preparation for graph-based SSL methods (if needed)\n",
    "# ============================================================\n",
    "if USE_PCA:\n",
    "    print(f\"Feature count = {n_features} > 100 — applying PCA (95% variance)\")\n",
    "    pca = PCA(n_components=0.95, random_state=42)\n",
    "    pca.fit(X_train_ssl)  # fit only on SSL training data\n",
    "    \n",
    "    X_train_ssl_pca = pca.transform(X_train_ssl)\n",
    "    X_test_s_pca = pca.transform(X_test_s)\n",
    "    \n",
    "    print(f\"  PCA components retained: {pca.n_components_}\")\n",
    "    print(f\"  Explained variance:      {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "    print(f\"  X_train_ssl_pca shape:   {X_train_ssl_pca.shape}\")\n",
    "    print(f\"  X_test_s_pca shape:      {X_test_s_pca.shape}\")\n",
    "else:\n",
    "    print(f\"Feature count = {n_features} <= 100 — using original features for graph-based methods.\")\n",
    "    X_train_ssl_pca = X_train_ssl.values\n",
    "    X_test_s_pca = X_test_s.values\n",
    "    pca = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f137389a",
   "metadata": {},
   "source": [
    "### Model B: Label Spreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Model B — Label Spreading (graph-based, KNN kernel)\n",
    "# ============================================================\n",
    "ls_clf = LabelSpreading(kernel=\"knn\", n_neighbors=10)\n",
    "ls_clf.fit(X_train_ssl_pca, y_train_ssl)\n",
    "\n",
    "pca_note = f\"PCA to {X_train_ssl_pca.shape[1]}d\" if USE_PCA else \"No PCA\"\n",
    "\n",
    "res_ls = evaluate_model(ls_clf, X_test_s_pca, y_test,\n",
    "                        \"LabelSpreading (SSL)\",\n",
    "                        notes=f\"kernel=knn, n_neighbors=10, {pca_note}\")\n",
    "results.append(res_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe759f",
   "metadata": {},
   "source": [
    "### Model C: Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3784279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Model C — Label Propagation (graph-based, KNN kernel)\n",
    "# ============================================================\n",
    "lp_clf = LabelPropagation(kernel=\"knn\", n_neighbors=10)\n",
    "lp_clf.fit(X_train_ssl_pca, y_train_ssl)\n",
    "\n",
    "res_lp = evaluate_model(lp_clf, X_test_s_pca, y_test,\n",
    "                        \"LabelPropagation (SSL)\",\n",
    "                        notes=f\"kernel=knn, n_neighbors=10, {pca_note}\")\n",
    "results.append(res_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6e32db",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6 — Comparison & Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 6 — Comparison table & best model selection\n",
    "# ============================================================\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\"model_name\": r[\"model_name\"], \"accuracy\": r[\"accuracy\"],\n",
    "     \"macro_f1\": r[\"macro_f1\"], \"notes\": r[\"notes\"]}\n",
    "    for r in results\n",
    "])\n",
    "\n",
    "# Sort by macro_f1 (primary) then accuracy (tiebreaker), descending\n",
    "comparison_df = comparison_df.sort_values(\n",
    "    [\"macro_f1\", \"accuracy\"], ascending=[False, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  MODEL COMPARISON TABLE\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Select best model\n",
    "best_idx = comparison_df.index[0]\n",
    "best_name = comparison_df.loc[best_idx, \"model_name\"]\n",
    "best_f1 = comparison_df.loc[best_idx, \"macro_f1\"]\n",
    "best_acc = comparison_df.loc[best_idx, \"accuracy\"]\n",
    "best_result = [r for r in results if r[\"model_name\"] == best_name][0]\n",
    "best_model = best_result[\"_model\"]\n",
    "\n",
    "print(f\"\\n>> BEST MODEL: {best_name}\")\n",
    "print(f\"   Macro F1:  {best_f1}\")\n",
    "print(f\"   Accuracy:  {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6bcd8b",
   "metadata": {},
   "source": [
    "## Step 7 — Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713dd8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 7a — Save comparison table\n",
    "# ============================================================\n",
    "comp_path = os.path.join(ARTIFACTS_DIR, \"ssl_model_comparison.csv\")\n",
    "comparison_df.to_csv(comp_path, index=False)\n",
    "print(f\"Saved comparison table: {comp_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176df200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 7b — Save best model and scaler\n",
    "# ============================================================\n",
    "model_path = os.path.join(ARTIFACTS_DIR, \"best_ssl_model.joblib\")\n",
    "scaler_path = os.path.join(ARTIFACTS_DIR, \"ssl_scaler.joblib\")\n",
    "\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"Saved best model ({best_name}): {model_path}\")\n",
    "\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"Saved scaler: {scaler_path}\")\n",
    "\n",
    "# Also save PCA if it was used\n",
    "if pca is not None:\n",
    "    pca_path = os.path.join(ARTIFACTS_DIR, \"ssl_pca.joblib\")\n",
    "    joblib.dump(pca, pca_path)\n",
    "    print(f\"Saved PCA: {pca_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e85d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 7c — Confusion matrix plot for best model\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix=best_result[\"_cm\"],\n",
    "    display_labels=[\"Low\", \"Medium\", \"High\", \"Blockbuster\"]\n",
    ").plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\n",
    "ax.set_title(f\"Confusion Matrix — {best_name}\\nMacro F1 = {best_f1}  |  Accuracy = {best_acc}\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "\n",
    "cm_path = os.path.join(ARTIFACTS_DIR, \"best_ssl_confusion_matrix.png\")\n",
    "fig.savefig(cm_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved confusion matrix plot: {cm_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec9b93",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Step | Description |\n",
    "|---|---|\n",
    "| Validation 1 | Leakage prevention — removed post-release features |\n",
    "| Validation 2 | Confirmed 4 revenue-tier classes |\n",
    "| Validation 3 | Documented unlabeled proportion |\n",
    "| Validation 4 | Checked dimensionality for PCA decision |\n",
    "| Validation 5 | Imputed missing values if any |\n",
    "| Split | 80/20 stratified on labeled data only |\n",
    "| Scaling | StandardScaler fitted on labeled train |\n",
    "| Baselines | GradientBoosting & RandomForest (supervised) |\n",
    "| SSL Models | SelfTraining, LabelSpreading, LabelPropagation |\n",
    "| Selection | Best model by macro F1 (accuracy as tiebreaker) |\n",
    "| Artifacts | Comparison CSV, best model, scaler, confusion matrix |\n",
    "\n",
    "**All evaluation was performed on a held-out labeled test set that never participated in pseudo-labeling.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
